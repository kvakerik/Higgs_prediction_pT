{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 15:41:42.877421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-12 15:41:42.889548: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-12 15:41:42.893167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n",
      "Found ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 15:41:45.702460: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4162_r15540_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4159_r15530_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "# test GPU\n",
    "# Import tensorflow and test if GPU is available\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# load data and convert them to awkward arrays using uproot\n",
    "import uproot\n",
    "\n",
    "\n",
    "# path to the signal and background files\n",
    "path_sig = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*VBFH*.root\"\n",
    "path_bkg = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*Ztt*.root\"\n",
    "\n",
    "# glob the files\n",
    "import glob\n",
    "files_sig = glob.glob(path_sig)\n",
    "files_bkg = glob.glob(path_bkg)\n",
    "\n",
    "print(\"Found\", files_sig)\n",
    "\n",
    "\n",
    "# define list of variable that we want to read from the files\n",
    "variables_higgs = [  \n",
    "    \"tau_0_p4\",\n",
    "    \"tau_1_p4\",\n",
    "    \"ditau_deta\",\"ditau_dphi\",\"ditau_dr\",\"ditau_higgspt\",\"ditau_scal_sum_pt\", #\"ditau_mmc_mlm_m\",\n",
    "    \"jet_0_p4\",\n",
    "    \"jet_1_p4\",\n",
    "    \"dijet_p4\", # fixme add dEta\n",
    "    \"met_p4\", \n",
    "    \"n_jets\",\"n_jets_30\",\"n_jets_40\",\"n_electrons\",\"n_muons\",\"n_taus\",\n",
    "]\n",
    "\n",
    "\n",
    "import vector\n",
    "import awkward as ak\n",
    "\n",
    "# use uproot to convert the root files to awkward arrays\n",
    "arrays = []\n",
    "for files in [files_sig, files_bkg]:\n",
    "    arrays.append([])\n",
    "    for file in files:\n",
    "        print(\"Reading file\", file)\n",
    "        f = uproot.open(file)['NOMINAL']\n",
    "        data = f.arrays(variables_higgs, library=\"ak\")\n",
    "        arr = []\n",
    "        for var in variables_higgs:\n",
    "            if 'p4' in var:\n",
    "                # We need to extract the 4-vector pt, eta, phi, mass\n",
    "                p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr.append(p4.rho) # pt\n",
    "                arr.append(p4.eta) # eta\n",
    "                arr.append(p4.phi) # phi\n",
    "                arr.append(p4.tau) # mass\n",
    "            \n",
    "            else:\n",
    "                arr.append(data[var])\n",
    "\n",
    "        arrays[-1].append(arr)    \n",
    "\n",
    "print(len(arrays[0]))\n",
    "print(len(arrays[1]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 (195502, 36) (195502,)\n",
      "0 1 (7156, 36) (7156,)\n",
      "0 2 (209617, 36) (209617,)\n",
      "0 3 (7282, 36) (7282,)\n",
      "0 4 (210515, 36) (210515,)\n",
      "0 5 (1844, 36) (1844,)\n",
      "0 6 (195498, 36) (195498,)\n",
      "0 7 (1878, 36) (1878,)\n",
      "1 0 (1, 36) (1,)\n",
      "1 1 (5619, 36) (5619,)\n",
      "1 2 (1092, 36) (1092,)\n",
      "1 3 (31486, 36) (31486,)\n",
      "1 4 (5, 36) (5,)\n",
      "1 5 (103, 36) (103,)\n",
      "1 6 (26, 36) (26,)\n",
      "1 7 (54, 36) (54,)\n",
      "1 8 (73851, 36) (73851,)\n",
      "1 9 (2694, 36) (2694,)\n",
      "1 10 (13107, 36) (13107,)\n",
      "1 11 (22, 36) (22,)\n",
      "Signal events: 829292\n",
      "Background events: 128060\n"
     ]
    }
   ],
   "source": [
    "# convert the awkward arrays to tensorflow tensors\n",
    "tensors = []\n",
    "labels = []\n",
    "n_events = []\n",
    "for i,arr_sample in enumerate(arrays):\n",
    "    n_evt = 0\n",
    "    tensors.append([])\n",
    "    labels.append([])\n",
    "    for j, arr_file in enumerate(arr_sample):\n",
    "        tensors_var = []\n",
    "        for arr_var in arr_file:\n",
    "            tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "            tensors_var.append(tensor)\n",
    "\n",
    "        # stack the tensors along the first axis\n",
    "        tensor_stack = tf.stack(tensors_var, axis=1)\n",
    "        tensors[-1].append(tensor_stack)\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # add the label\n",
    "        labels[-1].append(tf.constant(i==0, shape=(tensor.shape[0]), dtype=tf.int32)) # signal files go first, so i==0 is signal\n",
    "        print(i, j, tensors[-1][-1].shape, labels[-1][-1].shape)\n",
    "    n_events.append(n_evt)\n",
    "\n",
    "print(\"Signal events:\", n_events[0])\n",
    "print(\"Background events:\", n_events[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(36,), dtype=float32, numpy=\n",
      "array([ 4.75435562e+01,  1.62719214e+00,  5.07154644e-01,  2.33601554e-06,\n",
      "        2.86771793e+01,  1.62386715e+00, -1.35885978e+00,  1.05658375e-01,\n",
      "        3.32498550e-03,  1.86601448e+00,  1.86601734e+00,  7.98840256e+01,\n",
      "        7.62207336e+01,  9.79067383e+01,  7.68746872e+01, -5.88225007e-01,\n",
      "       -2.71475554e+00,  8.21009636e+00,  6.61246338e+01,  3.41954112e+00,\n",
      "        1.86800742e+00,  4.54609299e+00,  9.46995926e+01,  3.01311755e+00,\n",
      "        2.80362153e+00,  5.30990417e+02,  4.75952301e+01,  0.00000000e+00,\n",
      "       -1.26162064e+00,  7.29064504e-03,  2.00000000e+00,  2.00000000e+00,\n",
      "        2.00000000e+00,  0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(36,), dtype=float32, numpy=\n",
      "array([ 5.9510761e+01,  6.7389560e-01,  4.7589517e-01, -9.5367432e-07,\n",
      "        3.2608398e+01,  3.3506560e-01, -1.0794258e+00,  5.1099772e-04,\n",
      "        3.3882999e-01,  1.5553210e+00,  1.5918006e+00,  9.8846878e+01,\n",
      "        9.2119164e+01,  9.6727402e+01,  5.6478458e+01,  3.7383273e+00,\n",
      "        2.9710517e+00,  1.0984135e+01,  5.2207699e+01, -4.6755484e-01,\n",
      "        2.8277853e+00,  6.3737469e+00,  1.0840785e+02,  3.0663249e+00,\n",
      "        2.9022381e+00,  4.3931238e+02,  3.2419010e+01,  0.0000000e+00,\n",
      "       -4.3548813e-01,  2.8103634e-03,  3.0000000e+00,  2.0000000e+00,\n",
      "        2.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(36,), dtype=float32, numpy=\n",
      "array([ 3.2672932e+01, -5.0499111e-01,  4.3586013e-01,  6.7434956e-07,\n",
      "        6.2033741e+01, -1.2007509e+00,  1.8065865e+00,  5.1099859e-04,\n",
      "        6.9575983e-01,  1.3707263e+00,  1.5371963e+00,  1.7203154e+02,\n",
      "        9.4706673e+01,  1.2002688e+02,  1.2904448e+02,  1.4425223e+00,\n",
      "       -1.7605252e+00,  5.0928898e+00,  5.2445190e+01, -3.7600067e+00,\n",
      "       -1.5443070e+00,  2.1579186e-05,  1.8061931e+02, -2.2734296e+00,\n",
      "       -1.6981910e+00,  1.1031129e+03,  9.7703781e+01,  0.0000000e+00,\n",
      "        1.6176784e+00, -1.7450552e-02,  2.0000000e+00,  2.0000000e+00,\n",
      "        2.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(36,), dtype=float32, numpy=\n",
      "array([ 1.06627373e+02,  8.09739769e-01,  6.83270574e-01, -1.90734863e-06,\n",
      "        4.57801018e+01,  1.09750319e+00, -9.25439954e-01,  1.05658375e-01,\n",
      "        2.87763417e-01,  1.60871053e+00,  1.63424516e+00,  1.32374298e+02,\n",
      "        1.52407471e+02,  1.40302460e+02,  9.62700500e+01, -2.47654065e-01,\n",
      "        3.07703400e+00,  8.29026604e+00,  3.73139343e+01,  4.37012243e+00,\n",
      "       -2.60758066e+00,  3.24498940e+00,  1.28823944e+02,  3.11638021e+00,\n",
      "       -3.04221082e+00,  5.99148132e+02,  2.62221432e+01,  0.00000000e+00,\n",
      "       -6.25937045e-01, -2.08655186e-03,  3.00000000e+00,  2.00000000e+00,\n",
      "        1.00000000e+00,  0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(36,), dtype=float32, numpy=\n",
      "array([ 5.3350586e+01,  7.2684610e-01, -7.2196424e-01, -1.3486991e-06,\n",
      "        3.5942661e+01,  1.7826521e+00, -1.3706843e+00,  5.1099679e-04,\n",
      "        1.0558060e+00,  6.4872003e-01,  1.2391788e+00,  1.6367563e+02,\n",
      "        8.9293243e+01,  9.2025032e+01,  1.6891550e+02, -3.2004377e-01,\n",
      "        1.8111005e+00,  1.5024466e+01,  4.6836014e+01,  3.2524514e+00,\n",
      "       -1.5832102e+00,  3.0958440e+00,  1.2412085e+02,  2.1935017e+00,\n",
      "        1.9055903e+00,  5.4610895e+02,  7.8868416e+01,  0.0000000e+00,\n",
      "       -1.0045620e+00,  2.7509024e-02,  5.0000000e+00,  3.0000000e+00,\n",
      "        2.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# convert tensors to dataset\n",
    "d = []\n",
    "for tensors_sample, labels_sample in zip(tensors, labels):\n",
    "    d.append([])\n",
    "    for tensor_file, label_file in zip(tensors_sample, labels_sample):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((tensor_file, label_file))\n",
    "        d[-1].append(dataset)\n",
    "\n",
    "\n",
    "\n",
    "# combine the datasets using the sanple_from_datasets method\n",
    "# this will shuffle the events from all files into a single dataset\n",
    "datasets = []\n",
    "for i,datasets_sample in enumerate(d):\n",
    "    weights = [ x.shape[0] / n_events[i] for x in tensors[i] ]\n",
    "    dataset = tf.data.Dataset.sample_from_datasets(datasets_sample, weights=weights)\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# combine the signal and background datasets\n",
    "dataset = tf.data.Dataset.sample_from_datasets(datasets, weights=[0.5, 0.5], stop_on_empty_dataset=True)\n",
    "\n",
    "# printout the shape of the first event\n",
    "for x in dataset.take(5):\n",
    "    print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
