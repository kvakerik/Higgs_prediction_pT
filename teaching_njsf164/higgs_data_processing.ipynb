{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 15:17:15.600170: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-31 15:17:15.621313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-31 15:17:15.627922: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 15:17:19.198128: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root']\n",
      "Variables to load: ['jet_0_p4', 'jet_1_p4', 'tau_0', 'tau_0_q', 'tau_0_p4', 'met_p4', 'tau_1', 'tau_1_p4']\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Sample 0 has 1 files\n",
      "File 0 has 4 Objects\n",
      "Object 0 has 11 variables\n",
      "Object 1 has 11 variables\n",
      "Object 2 has 11 variables\n",
      "Object 3 has 11 variables\n",
      "Sample 1 has 1 files\n",
      "File 0 has 4 Objects\n",
      "Object 0 has 11 variables\n",
      "Object 1 has 11 variables\n",
      "Object 2 has 11 variables\n",
      "Object 3 has 11 variables\n"
     ]
    }
   ],
   "source": [
    "# Starting with Dan's code for loading data from root files\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "# test GPU\n",
    "# Import tensorflow and test if GPU is available\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# load data and convert them to awkward arrays using uproot\n",
    "import uproot\n",
    "import vector\n",
    "import awkward as ak\n",
    "\n",
    "# path to the signal and background files\n",
    "path_sig = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*VBFH*.root\"\n",
    "path_bkg = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*Ztt*.root\"\n",
    "\n",
    "# glob the files\n",
    "import glob\n",
    "files_sig = glob.glob(path_sig)\n",
    "files_bkg = glob.glob(path_bkg)\n",
    "\n",
    "# hack: only use the first file\n",
    "files_sig = files_sig[:1]\n",
    "files_bkg = files_bkg[:1]\n",
    "\n",
    "print(\"Found\", files_sig)\n",
    "\n",
    "variables_higgs = [  \n",
    "    [\"tau_0_p4\", \"tau_0_q\", \"met_p4\", 'tau_0', 0.],\n",
    "    [\"tau_1_p4\", \"tau_0_q\", \"met_p4\", 'tau_1', 0.],\n",
    "    # \"ditau_deta\",\"ditau_dphi\",\"ditau_dr\",\"ditau_higgspt\",\"ditau_scal_sum_pt\", #\"ditau_mmc_mlm_m\",\n",
    "    [\"jet_0_p4\", 0., \"met_p4\", 0., 0., 0., 1.],\n",
    "    [\"jet_1_p4\", 0., \"met_p4\", 0., 0., 0., 1.],\n",
    "    # \"dijet_p4\", # fixme add dEta\n",
    "    # \"met_p4\", \n",
    "    # \"n_jets\",\"n_jets_30\",\"n_jets_40\",\"n_electrons\",\"n_muons\",\"n_taus\",\n",
    "]\n",
    "\n",
    "variable_names = list(set([var for vars in variables_higgs for var in vars if isinstance(var, str)]))\n",
    "print(\"Variables to load:\", variable_names)\n",
    "\n",
    "arrays = []\n",
    "for files in [files_sig, files_bkg]:\n",
    "    arrays.append([])\n",
    "    for file in files:\n",
    "        print(\"Reading file\", file)\n",
    "        f = uproot.open(file)['NOMINAL']\n",
    "        data = f.arrays(variable_names, library=\"ak\")\n",
    "        files_arr = []\n",
    "        for vars in variables_higgs:\n",
    "            objects_arr = []\n",
    "            for var in vars:\n",
    "                if isinstance(var, str):                    \n",
    "                    if 'p4' in var:\n",
    "                        # We need to extract the 4-vector pt, eta, phi, mass\n",
    "                        p4 = vector.zip({'x': data[var]['fP']['fX'],\n",
    "                                        'y': data[var]['fP']['fY'],\n",
    "                                        'z': data[var]['fP']['fZ'],\n",
    "                                        't': data[var]['fE']})\n",
    "\n",
    "                        if 'met' not in var:\n",
    "                            objects_arr.append(p4.rho)  # pt\n",
    "                            objects_arr.append(p4.eta)  # eta\n",
    "                            objects_arr.append(p4.phi)  # phi\n",
    "                            objects_arr.append(p4.tau)  # mass\n",
    "                        else:\n",
    "                            objects_arr.append(p4.rho)  # pt\n",
    "                            objects_arr.append(p4.phi)  # phi\n",
    "\n",
    "                    \n",
    "                    elif var in  ['tau_0', 'tau_1']:\n",
    "                        isMuon = data[var] == 1\n",
    "                        isElec = data[var] == 2\n",
    "                        isHadr = data[var] == 3\n",
    "                        objects_arr.append(isMuon)\n",
    "                        objects_arr.append(isElec)\n",
    "                        objects_arr.append(isHadr)\n",
    "                        \n",
    "                    else:\n",
    "                        objects_arr.append(data[var])\n",
    "                else:\n",
    "                    objects_arr.append(var)\n",
    "\n",
    "            files_arr.append(objects_arr)\n",
    "        arrays[-1].append(files_arr)\n",
    "\n",
    "for i,sample_arrays in enumerate(arrays):\n",
    "    print(\"Sample\", i, \"has\", len(sample_arrays), \"files\")\n",
    "    for j,file_arrays in enumerate(sample_arrays):\n",
    "        print(\"File\", j, \"has\", len(file_arrays), \"Objects\")\n",
    "        for k,array in enumerate(file_arrays):\n",
    "            print(\"Object\", k, \"has\", len(array), \"variables\")\n",
    "            # for l,object in enumerate(array):\n",
    "            #     print(\"Object\", l, \"has\", len(object), \"entries\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 (195502, 11)\n",
      "0 0 1 (195502, 11)\n",
      "0 0 2 (195502, 11)\n",
      "0 0 3 (195502, 11)\n",
      "0 0 (195502, 4, 11) (195502,)\n",
      "1 0 0 (1, 11)\n",
      "1 0 1 (1, 11)\n",
      "1 0 2 (1, 11)\n",
      "1 0 3 (1, 11)\n",
      "1 0 (1, 4, 11) (1,)\n",
      "Signal events: 195502\n",
      "Background events: 1\n"
     ]
    }
   ],
   "source": [
    "# convert the awkward arrays to tensorflow tensors\n",
    "tensors = []\n",
    "labels = []\n",
    "n_events = []\n",
    "for i,arr_sample in enumerate(arrays):\n",
    "    n_evt = 0\n",
    "    tensors.append([])\n",
    "    labels.append([])\n",
    "    for j, arr_file in enumerate(arr_sample):\n",
    "        n_evt_file = None\n",
    "        tensors_object = []\n",
    "        for k, arr_object in enumerate(arr_file):\n",
    "            tensors_var = []\n",
    "            for arr_var in arr_object:\n",
    "                if isinstance(arr_var, (float, int)):\n",
    "                    tensor = tf.constant(arr_var, shape=(n_evt_file,), dtype=tf.float32) \n",
    "                else:\n",
    "                    tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "                    if n_evt_file is None:\n",
    "                        n_evt_file = tensor.shape[0]\n",
    "                \n",
    "                tensors_var.append(tensor)\n",
    "\n",
    "            # stack object variables along the last axis\n",
    "            tensor_object = tf.stack(tensors_var, axis=-1)\n",
    "            tensors_object.append(tensor_object)\n",
    "            print(i, j, k, tensor_object.shape)\n",
    "\n",
    "        # stack the tensors along the axis 1\n",
    "        tensor_stack = tf.stack(tensors_object, axis=1)\n",
    "        tensors[-1].append(tensor_stack)\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # add the label\n",
    "        labels[-1].append(tf.constant(i==0, shape=(tensor_stack.shape[0],), dtype=tf.int32)) # signal files go first, so i==0 is signal\n",
    "        print(i, j, tensors[-1][-1].shape, labels[-1][-1].shape)\n",
    "    \n",
    "    n_events.append(n_evt)\n",
    "\n",
    "print(\"Signal events:\", n_events[0])\n",
    "print(\"Background events:\", n_events[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([34.244442], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = tensors[-1][-1]\n",
    "print(t[:, 0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
