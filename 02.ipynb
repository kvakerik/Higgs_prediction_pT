{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 02:47:28.294622: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-02 02:47:28.316712: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-02 02:47:28.323496: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n",
      "Found ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 02:47:32.376053: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root']\n",
      "Data shape (events)(variables) : 195502 18\n",
      "Data shape (events)(variables) : 7156 18\n",
      "Data shape (events)(variables) : 209617 18\n",
      "Data shape (events)(variables) : 7282 18\n",
      "Data shape (events)(variables) : 210515 18\n",
      "Data shape (events)(variables) : 1844 18\n",
      "Data shape (events)(variables) : 195498 18\n",
      "Data shape (events)(variables) : 1878 18\n",
      "Reading file  ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4162_r15540_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4159_r15530_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root']\n",
      "Data shape (events)(variables) : 1 18\n",
      "Data shape (events)(variables) : 5619 18\n",
      "Data shape (events)(variables) : 1092 18\n",
      "Data shape (events)(variables) : 31486 18\n",
      "Data shape (events)(variables) : 5 18\n",
      "Data shape (events)(variables) : 103 18\n",
      "Data shape (events)(variables) : 26 18\n",
      "Data shape (events)(variables) : 54 18\n",
      "Data shape (events)(variables) : 73851 18\n",
      "Data shape (events)(variables) : 2694 18\n",
      "Data shape (events)(variables) : 13107 18\n",
      "Data shape (events)(variables) : 22 18\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "# test GPU\n",
    "# Import tensorflow and test if GPU is available\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# load data and convert them to awkward arrays using uproot\n",
    "import uproot\n",
    "\n",
    "\n",
    "# path to the signal and background files\n",
    "path_sig = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*VBFH*.root\"\n",
    "path_bkg = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*Ztt*.root\"\n",
    "\n",
    "# glob the files\n",
    "import glob\n",
    "files_sig = glob.glob(path_sig)\n",
    "files_bkg = glob.glob(path_bkg)\n",
    "\n",
    "print(\"Found\", files_sig)\n",
    "\n",
    "\n",
    "# define list of variable that we want to read from the files\n",
    "variables_higgs = [  \n",
    "    \"tau_0_p4\",\n",
    "    \"tau_1_p4\",\n",
    "    \"ditau_deta\",\"ditau_dphi\",\"ditau_dr\",\"ditau_higgspt\",\"ditau_scal_sum_pt\", #\"ditau_mmc_mlm_m\",\n",
    "    \"jet_0_p4\",\n",
    "    \"jet_1_p4\",\n",
    "    \"dijet_p4\", # fixme add dEta\n",
    "    \"met_p4\", \n",
    "    \"n_jets\",\"n_jets_30\",\"n_jets_40\",\"n_electrons\",\"n_muons\",\"n_taus\",\n",
    "    \"boson_0_truth_p4\"\n",
    "]\n",
    "import vector\n",
    "import awkward as ak\n",
    "\n",
    "# use uproot to convert the root files to awkward arrays\n",
    "arrays = []\n",
    "arrays_truth = []\n",
    "for files in [files_sig, files_bkg]:\n",
    "    arrays.append([])\n",
    "    arrays_truth.append([])\n",
    "    print(\"Reading file \", files)\n",
    "    for file in files:\n",
    "        f = uproot.open(file)['NOMINAL']\n",
    "        data = f.arrays(variables_higgs, library=\"ak\")\n",
    "        print(\"Data shape (events)(variables) :\",len(data),len(data.fields))\n",
    "        arr = []\n",
    "        arr_truth = []\n",
    "        for var in variables_higgs:\n",
    "            if ('p4' in var) and (var != \"boson_0_truth_p4\"):\n",
    "                # We need to extract the 4-vector pt, eta, phi, mass\n",
    "                p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr.append(p4.rho) # pt\n",
    "                arr.append(p4.eta) # eta\n",
    "                arr.append(p4.phi) # phi\n",
    "                arr.append(p4.tau) # mass\n",
    "\n",
    "            elif (var == \"boson_0_truth_p4\"):\n",
    "                target_p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr_truth.append(target_p4.rho) # pt\n",
    "                arr_truth.append(target_p4.eta) # eta\n",
    "                arr_truth.append(target_p4.phi) # phi\n",
    "                arr_truth.append(target_p4.tau) # mass\n",
    "                \n",
    "            else:\n",
    "                arr.append(data[var])\n",
    "        arrays[-1].append(arr)\n",
    "        arrays_truth[-1].append(arr_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "File 0 contains 8 blocks\n",
      "Block 0: Shape of matica: (195502, 35)\n",
      "Block 1: Shape of matica: (7156, 35)\n",
      "Block 2: Shape of matica: (209617, 35)\n",
      "Block 3: Shape of matica: (7282, 35)\n",
      "Block 4: Shape of matica: (210515, 35)\n",
      "Block 5: Shape of matica: (1844, 35)\n",
      "Block 6: Shape of matica: (195498, 35)\n",
      "Block 7: Shape of matica: (1878, 35)\n",
      "File 1 contains 12 blocks\n",
      "Block 0: Shape of matica: (1, 35)\n",
      "Block 1: Shape of matica: (5619, 35)\n",
      "Block 2: Shape of matica: (1092, 35)\n",
      "Block 3: Shape of matica: (31486, 35)\n",
      "Block 4: Shape of matica: (5, 35)\n",
      "Block 5: Shape of matica: (103, 35)\n",
      "Block 6: Shape of matica: (26, 35)\n",
      "Block 7: Shape of matica: (54, 35)\n",
      "Block 8: Shape of matica: (73851, 35)\n",
      "Block 9: Shape of matica: (2694, 35)\n",
      "Block 10: Shape of matica: (13107, 35)\n",
      "Block 11: Shape of matica: (22, 35)\n",
      "--------------------------------------------------\n",
      "File 0 contains 8 blocks\n",
      "Block 0: Shape of matica: (195502, 4)\n",
      "Block 1: Shape of matica: (7156, 4)\n",
      "Block 2: Shape of matica: (209617, 4)\n",
      "Block 3: Shape of matica: (7282, 4)\n",
      "Block 4: Shape of matica: (210515, 4)\n",
      "Block 5: Shape of matica: (1844, 4)\n",
      "Block 6: Shape of matica: (195498, 4)\n",
      "Block 7: Shape of matica: (1878, 4)\n",
      "File 1 contains 12 blocks\n",
      "Block 0: Shape of matica: (1, 4)\n",
      "Block 1: Shape of matica: (5619, 4)\n",
      "Block 2: Shape of matica: (1092, 4)\n",
      "Block 3: Shape of matica: (31486, 4)\n",
      "Block 4: Shape of matica: (5, 4)\n",
      "Block 5: Shape of matica: (103, 4)\n",
      "Block 6: Shape of matica: (26, 4)\n",
      "Block 7: Shape of matica: (54, 4)\n",
      "Block 8: Shape of matica: (73851, 4)\n",
      "Block 9: Shape of matica: (2694, 4)\n",
      "Block 10: Shape of matica: (13107, 4)\n",
      "Block 11: Shape of matica: (22, 4)\n"
     ]
    }
   ],
   "source": [
    "# awkward arrays tensors\n",
    "# Čisto na shape jednotlivých blokov pre arrays a arrays_truth\n",
    "for arr in [arrays, arrays_truth]:\n",
    "    print(\"-\" * 50)\n",
    "    for j, arr_file in enumerate(arr):\n",
    "        arrays_j = arr_file\n",
    "        print(f\"File {j} contains {len(arrays_j)} blocks\")\n",
    "        for i, arr_data in enumerate(arrays_j):\n",
    "            # Kontrola, či je arr_data iterovateľný\n",
    "            if isinstance(arr_data, (list, ak.Array, np.ndarray)):\n",
    "                num_rows = len(arr_data[0]) if len(arr_data) > 0 and hasattr(arr_data[0], \"__len__\") else 1\n",
    "                num_columns = len(arr_data)\n",
    "                print(f\"Block {i}: Shape of matica: ({num_rows}, {num_columns})\")\n",
    "            else:\n",
    "                # Ak je skalár\n",
    "                print(f\"Block {i}: Scalar value of type {type(arr_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 (195502, 35) (195502, 4)\n",
      "0 1 (7156, 35) (7156, 4)\n",
      "0 2 (209617, 35) (209617, 4)\n",
      "0 3 (7282, 35) (7282, 4)\n",
      "0 4 (210515, 35) (210515, 4)\n",
      "0 5 (1844, 35) (1844, 4)\n",
      "0 6 (195498, 35) (195498, 4)\n",
      "0 7 (1878, 35) (1878, 4)\n",
      "1 0 (1, 35) (1, 4)\n",
      "1 1 (5619, 35) (5619, 4)\n",
      "1 2 (1092, 35) (1092, 4)\n",
      "1 3 (31486, 35) (31486, 4)\n",
      "1 4 (5, 35) (5, 4)\n",
      "1 5 (103, 35) (103, 4)\n",
      "1 6 (26, 35) (26, 4)\n",
      "1 7 (54, 35) (54, 4)\n",
      "1 8 (73851, 35) (73851, 4)\n",
      "1 9 (2694, 35) (2694, 4)\n",
      "1 10 (13107, 35) (13107, 4)\n",
      "1 11 (22, 35) (22, 4)\n",
      "Signal events: 829292\n",
      "Background events: 128060\n"
     ]
    }
   ],
   "source": [
    "# Premena awkward arrays na tensorflow tensors s truth vektormi\n",
    "import tensorflow as tf\n",
    "import awkward as ak\n",
    "\n",
    "tensors = []\n",
    "truth_vectors = []\n",
    "n_events = []\n",
    "\n",
    "# Iterácia cez signal a background datasets\n",
    "for i, (arr_sample, arr_truth_sample) in enumerate(zip(arrays, arrays_truth)):\n",
    "    n_evt = 0\n",
    "    tensors.append([])\n",
    "    truth_vectors.append([])\n",
    "    \n",
    "    for j, (arr_file, arr_truth_file) in enumerate(zip(arr_sample, arr_truth_sample)):\n",
    "        tensors_var = []\n",
    "        truths_var = []\n",
    "\n",
    "        # Iterácia cez jednotlivé premenné a truth vektory\n",
    "        for arr_var in arr_file:\n",
    "            # Konverzia premenných na tensorflow tenzory\n",
    "            tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "            tensors_var.append(tensor)\n",
    "        \n",
    "        for truth_var in arr_truth_file:\n",
    "            # Konverzia truth na tensorflow tensor\n",
    "            truth_tensor = tf.constant(ak.to_numpy(truth_var), dtype=tf.float32)\n",
    "            truths_var.append(truth_tensor)\n",
    "\n",
    "        # Stack premenných\n",
    "        tensor_stack = tf.stack(tensors_var, axis=1)  # Premenné (napr. 35 stĺpcov)\n",
    "        truth_stack = tf.stack(truths_var, axis=1)    # Pravdivostné vektory (napr. 4 stĺpce)\n",
    "\n",
    "        # Pridanie do zoznamov\n",
    "        tensors[-1].append(tensor_stack)\n",
    "        truth_vectors[-1].append(truth_stack)\n",
    "\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # Výstup pre kontrolu\n",
    "        print(i, j, tensor_stack.shape, truth_stack.shape)\n",
    "\n",
    "    n_events.append(n_evt)\n",
    "\n",
    "# Výpis celkových počtov udalostí\n",
    "print(\"Signal events:\", n_events[0])\n",
    "print(\"Background events:\", n_events[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 (195502, 35) (195502,)\n",
      "0 1 (7156, 35) (7156,)\n",
      "0 2 (209617, 35) (209617,)\n",
      "0 3 (7282, 35) (7282,)\n",
      "0 4 (210515, 35) (210515,)\n",
      "0 5 (1844, 35) (1844,)\n",
      "0 6 (195498, 35) (195498,)\n",
      "0 7 (1878, 35) (1878,)\n",
      "1 0 (1, 35) (1,)\n",
      "1 1 (5619, 35) (5619,)\n",
      "1 2 (1092, 35) (1092,)\n",
      "1 3 (31486, 35) (31486,)\n",
      "1 4 (5, 35) (5,)\n",
      "1 5 (103, 35) (103,)\n",
      "1 6 (26, 35) (26,)\n",
      "1 7 (54, 35) (54,)\n",
      "1 8 (73851, 35) (73851,)\n",
      "1 9 (2694, 35) (2694,)\n",
      "1 10 (13107, 35) (13107,)\n",
      "1 11 (22, 35) (22,)\n",
      "Signal events: 829292\n",
      "Background events: 128060\n",
      "2\n",
      "<class 'list'>\n",
      "tf.Tensor(\n",
      "[[47.543556    1.6271921   0.50715464 ...  0.          1.\n",
      "   1.        ]\n",
      " [53.350586    0.7268461  -0.72196424 ...  1.          0.\n",
      "   1.        ]\n",
      " [62.28143     0.49770078  1.5526772  ...  0.          1.\n",
      "   1.        ]\n",
      " ...\n",
      " [34.928345   -0.8959155  -0.98953533 ...  0.          1.\n",
      "   1.        ]\n",
      " [47.789715    0.8239082   2.8537514  ...  1.          0.\n",
      "   1.        ]\n",
      " [65.47977     1.2410988   3.1411672  ...  1.          0.\n",
      "   1.        ]], shape=(195502, 35), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# convert the awkward arrays to tensorflow tensors\n",
    "tensors = []\n",
    "labels = []\n",
    "n_events = []\n",
    "for i,arr_sample in enumerate(arrays):\n",
    "    n_evt = 0\n",
    "    tensors.append([])\n",
    "    labels.append([])\n",
    "    for j, arr_file in enumerate(arr_sample):\n",
    "        tensors_var = []\n",
    "        for arr_var in arr_file:\n",
    "            tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "            tensors_var.append(tensor)\n",
    "\n",
    "        # stack the tensors along the first axis\n",
    "        tensor_stack = tf.stack(tensors_var, axis=1)\n",
    "        tensors[-1].append(tensor_stack)\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # add the label\n",
    "        labels[-1].append(tf.constant(i==0, shape=(tensor.shape[0]), dtype=tf.int32)) # signal files go first, so i==0 is signal\n",
    "        print(i, j, tensors[-1][-1].shape, labels[-1][-1].shape)\n",
    "    n_events.append(n_evt)\n",
    "\n",
    "print(\"Signal events:\", n_events[0])\n",
    "print(\"Background events:\", n_events[1])\n",
    "print(len(tensors))\n",
    "print(type(tensors))\n",
    "print(tensors[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "20\n",
      "<class 'tensorflow.python.data.ops.directed_interleave_op._DirectedInterleaveDataset'>\n",
      "tf.Tensor(47.543556, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# convert tensors to dataset\n",
    "# Creating a unified list of datasets without distinguishing between signal and background\n",
    "print(type(tensors))\n",
    "print(type(tensors[0]))\n",
    "print(type(tensors[0][0]))\n",
    "\n",
    "datasets = []\n",
    "for tensors_sample in tensors:\n",
    "    #print(type(tensors_sample))\n",
    "    #print(len(tensors_sample))\n",
    "    for tensor_file in tensors_sample:\n",
    "        #print(type(tensor_file))\n",
    "        #print(len(tensor_file))\n",
    "        dataset_sample = tf.data.Dataset.from_tensor_slices((tensor_file))\n",
    "        datasets.append(dataset_sample)\n",
    "\n",
    "print(len(datasets))\n",
    "#print(type(dataset))\n",
    "#print(tensors[0][1])\n",
    "# Print number of datasets\n",
    "#print(len(dataset))\n",
    "weights_list = []\n",
    "for i in range(len(tensors)):\n",
    "    weights = [ x.shape[0] / n_events[i] for x in tensors[i]]\n",
    "    weights_list.extend(weights)\n",
    "\n",
    "#print(weights_list)\n",
    "#print(len(weights_list))\n",
    "dataset = tf.data.Dataset.sample_from_datasets(datasets, weights=weights_list)\n",
    "# Combine the datasets using sample_from_datasets method\n",
    "# This will shuffle the events from all datasets into a single dataset\n",
    "\n",
    "print(type(dataset))\n",
    "# Printout the shape of the first event\n",
    "for x in dataset.take(1):\n",
    "    print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
