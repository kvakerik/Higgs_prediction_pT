{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:37:22.850109: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 11:37:22.870596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 11:37:22.876973: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n",
      "All files ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4162_r15540_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4159_r15530_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 11:37:26.589813: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (events)(variables) : 195502 18\n",
      "Data shape (events)(variables) : 7156 18\n",
      "Data shape (events)(variables) : 209617 18\n",
      "Data shape (events)(variables) : 7282 18\n",
      "Data shape (events)(variables) : 210515 18\n",
      "Data shape (events)(variables) : 1844 18\n",
      "Data shape (events)(variables) : 195498 18\n",
      "Data shape (events)(variables) : 1878 18\n",
      "Data shape (events)(variables) : 1 18\n",
      "Data shape (events)(variables) : 5619 18\n",
      "Data shape (events)(variables) : 1092 18\n",
      "Data shape (events)(variables) : 31486 18\n",
      "Data shape (events)(variables) : 5 18\n",
      "Data shape (events)(variables) : 103 18\n",
      "Data shape (events)(variables) : 26 18\n",
      "Data shape (events)(variables) : 54 18\n",
      "Data shape (events)(variables) : 73851 18\n",
      "Data shape (events)(variables) : 2694 18\n",
      "Data shape (events)(variables) : 13107 18\n",
      "Data shape (events)(variables) : 22 18\n",
      "arrays 20\n",
      "arrays_truth 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "# test GPU\n",
    "# Import tensorflow and test if GPU is available\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# load data and convert them to awkward arrays using uproot\n",
    "import uproot\n",
    "\n",
    "\n",
    "# path to the signal and background files\n",
    "path_sig = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*VBFH*.root\"\n",
    "path_bkg = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*Ztt*.root\"\n",
    "\n",
    "# glob the files\n",
    "import glob\n",
    "files_sig = glob.glob(path_sig)\n",
    "files_bkg = glob.glob(path_bkg)\n",
    "all_files = files_sig + files_bkg\n",
    "\n",
    "print(\"All files\", all_files)\n",
    "\n",
    "\n",
    "# define list of variable that we want to read from the files\n",
    "variables_higgs = [  \n",
    "    \"tau_0_p4\",\n",
    "    \"tau_1_p4\",\n",
    "    \"ditau_deta\",\"ditau_dphi\",\"ditau_dr\",\"ditau_higgspt\",\"ditau_scal_sum_pt\", #\"ditau_mmc_mlm_m\",\n",
    "    \"jet_0_p4\",\n",
    "    \"jet_1_p4\",\n",
    "    \"dijet_p4\", # fixme add dEta\n",
    "    \"met_p4\", \n",
    "    \"n_jets\",\"n_jets_30\",\"n_jets_40\",\"n_electrons\",\"n_muons\",\"n_taus\",\n",
    "    \"boson_0_truth_p4\"\n",
    "]\n",
    "import vector\n",
    "import awkward as ak\n",
    "\n",
    "# use uproot to convert the root files to awkward arrays\n",
    "arrays = []\n",
    "arrays_truth = []\n",
    "# for files in [files_sig, files_bkg]:\n",
    "#     arrays.append([])\n",
    "#     arrays_truth.append([])\n",
    "#     print(\"Reading file \", files)\n",
    "for file in all_files:\n",
    "        f = uproot.open(file)['NOMINAL']\n",
    "        data = f.arrays(variables_higgs, library=\"ak\")\n",
    "        print(\"Data shape (events)(variables) :\",len(data),len(data.fields))\n",
    "        arr = []\n",
    "        arr_truth = []\n",
    "        for var in variables_higgs:\n",
    "            if ('p4' in var) and (var != \"boson_0_truth_p4\"):\n",
    "                # We need to extract the 4-vector pt, eta, phi, mass\n",
    "                p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr.append(p4.rho) # pt\n",
    "                arr.append(p4.eta) # eta\n",
    "                arr.append(p4.phi) # phi\n",
    "                arr.append(p4.tau) # mass\n",
    "\n",
    "            elif (var == \"boson_0_truth_p4\"):\n",
    "                target_p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr_truth.append(target_p4.rho) # pt\n",
    "                arr_truth.append(target_p4.eta) # eta\n",
    "                arr_truth.append(target_p4.phi) # phi\n",
    "                arr_truth.append(target_p4.tau) # mass\n",
    "                \n",
    "            else:\n",
    "                arr.append(data[var])\n",
    "        arrays.append(arr)\n",
    "        arrays_truth.append(arr_truth)\n",
    "\n",
    "print(\"arrays\", len(arrays))\n",
    "print(\"arrays_truth\",len(arrays_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Block 0: Shape of matrix: (195502, 35)\n",
      "Block 1: Shape of matrix: (7156, 35)\n",
      "Block 2: Shape of matrix: (209617, 35)\n",
      "Block 3: Shape of matrix: (7282, 35)\n",
      "Block 4: Shape of matrix: (210515, 35)\n",
      "Block 5: Shape of matrix: (1844, 35)\n",
      "Block 6: Shape of matrix: (195498, 35)\n",
      "Block 7: Shape of matrix: (1878, 35)\n",
      "Block 8: Shape of matrix: (1, 35)\n",
      "Block 9: Shape of matrix: (5619, 35)\n",
      "Block 10: Shape of matrix: (1092, 35)\n",
      "Block 11: Shape of matrix: (31486, 35)\n",
      "Block 12: Shape of matrix: (5, 35)\n",
      "Block 13: Shape of matrix: (103, 35)\n",
      "Block 14: Shape of matrix: (26, 35)\n",
      "Block 15: Shape of matrix: (54, 35)\n",
      "Block 16: Shape of matrix: (73851, 35)\n",
      "Block 17: Shape of matrix: (2694, 35)\n",
      "Block 18: Shape of matrix: (13107, 35)\n",
      "Block 19: Shape of matrix: (22, 35)\n",
      "--------------------------------------------------\n",
      "Block 0: Shape of matrix: (195502, 4)\n",
      "Block 1: Shape of matrix: (7156, 4)\n",
      "Block 2: Shape of matrix: (209617, 4)\n",
      "Block 3: Shape of matrix: (7282, 4)\n",
      "Block 4: Shape of matrix: (210515, 4)\n",
      "Block 5: Shape of matrix: (1844, 4)\n",
      "Block 6: Shape of matrix: (195498, 4)\n",
      "Block 7: Shape of matrix: (1878, 4)\n",
      "Block 8: Shape of matrix: (1, 4)\n",
      "Block 9: Shape of matrix: (5619, 4)\n",
      "Block 10: Shape of matrix: (1092, 4)\n",
      "Block 11: Shape of matrix: (31486, 4)\n",
      "Block 12: Shape of matrix: (5, 4)\n",
      "Block 13: Shape of matrix: (103, 4)\n",
      "Block 14: Shape of matrix: (26, 4)\n",
      "Block 15: Shape of matrix: (54, 4)\n",
      "Block 16: Shape of matrix: (73851, 4)\n",
      "Block 17: Shape of matrix: (2694, 4)\n",
      "Block 18: Shape of matrix: (13107, 4)\n",
      "Block 19: Shape of matrix: (22, 4)\n"
     ]
    }
   ],
   "source": [
    "# awkward arrays tensors\n",
    "# Čisto na shape jednotlivých blokov pre arrays a arrays_truth\n",
    "for arr in [arrays, arrays_truth]:\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, arr_data in enumerate(arr):\n",
    "            # Kontrola, či je arr_data iterovateľný\n",
    "            if isinstance(arr_data, (list, ak.Array, np.ndarray)):\n",
    "                num_rows = len(arr_data[0]) if len(arr_data) > 0 and hasattr(arr_data[0], \"__len__\") else 1\n",
    "                num_columns = len(arr_data)\n",
    "                print(f\"Block {i}: Shape of matrix: ({num_rows}, {num_columns})\")\n",
    "            else:\n",
    "                # Ak je skalár\n",
    "                print(f\"Block {i}: Scalar value of type {type(arr_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (195502, 35) (195502, 4)\n",
      "1 (7156, 35) (7156, 4)\n",
      "2 (209617, 35) (209617, 4)\n",
      "3 (7282, 35) (7282, 4)\n",
      "4 (210515, 35) (210515, 4)\n",
      "5 (1844, 35) (1844, 4)\n",
      "6 (195498, 35) (195498, 4)\n",
      "7 (1878, 35) (1878, 4)\n",
      "8 (1, 35) (1, 4)\n",
      "9 (5619, 35) (5619, 4)\n",
      "10 (1092, 35) (1092, 4)\n",
      "11 (31486, 35) (31486, 4)\n",
      "12 (5, 35) (5, 4)\n",
      "13 (103, 35) (103, 4)\n",
      "14 (26, 35) (26, 4)\n",
      "15 (54, 35) (54, 4)\n",
      "16 (73851, 35) (73851, 4)\n",
      "17 (2694, 35) (2694, 4)\n",
      "18 (13107, 35) (13107, 4)\n",
      "19 (22, 35) (22, 4)\n",
      "Tensors: 20\n",
      "Truth_vectors: 20\n",
      "Events: [195502, 7156, 209617, 7282, 210515, 1844, 195498, 1878, 1, 5619, 1092, 31486, 5, 103, 26, 54, 73851, 2694, 13107, 22]\n",
      "Total events 957352\n"
     ]
    }
   ],
   "source": [
    "# Premena awkward arrays na tensorflow tensors s truth vektormi\n",
    "tensors = []\n",
    "truth_vectors = []\n",
    "n_events = []\n",
    "\n",
    "# Iterácia cez signal a background datasets\n",
    "for j, (arr_file, arr_truth_file) in enumerate(zip(arrays, arrays_truth)):\n",
    "        tensors_var = []\n",
    "        truths_var = []\n",
    "        n_evt = 0\n",
    "\n",
    "        # Iterácia cez jednotlivé premenné a truth vektory\n",
    "        for arr_var in arr_file:\n",
    "            # Konverzia premenných na tensorflow tenzory\n",
    "            tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "            tensors_var.append(tensor)\n",
    "        \n",
    "        for truth_var in arr_truth_file:\n",
    "            # Konverzia truth na tensorflow tensor\n",
    "            truth_tensor = tf.constant(ak.to_numpy(truth_var), dtype=tf.float32)\n",
    "            truths_var.append(truth_tensor)\n",
    "    \n",
    "        # Stack premenných\n",
    "        tensor_stack = tf.stack(tensors_var, axis=1)  # Premenné (napr. 35 stĺpcov)\n",
    "        truth_stack = tf.stack(truths_var, axis=1)    # Pravdivostné vektory (napr. 4 stĺpce)\n",
    "\n",
    "        # Pridanie do zoznamov\n",
    "        tensors.append(tensor_stack)\n",
    "        truth_vectors.append(truth_stack)\n",
    "\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # Výstup pre kontrolu\n",
    "        print(j, tensor_stack.shape, truth_stack.shape)\n",
    "\n",
    "        n_events.append(n_evt)\n",
    "\n",
    "# Výpis celkových počtov udalostí\n",
    "print(\"Tensors:\", len(tensors))\n",
    "print(\"Truth_vectors:\", len(truth_vectors))\n",
    "print(\"Events:\", n_events)\n",
    "print(\"Total events\", np.sum(n_events))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "195502\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "7156\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "209617\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "7282\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "210515\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1844\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "195498\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1878\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "5619\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1092\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "31486\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "103\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "26\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "54\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "73851\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "2694\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "13107\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# convert tensors to dataset\n",
    "# Creating a unified list of datasets without distinguishing between signal and background\n",
    "# print(type(tensors))\n",
    "# print(type(tensors[0]))\n",
    "# print(type(tensors[0][0]))\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for tensor_file, truth_file in zip(tensors,truth_vectors):\n",
    "        # print(type(tensor_file))\n",
    "        # print(len(tensor_file))\n",
    "        dataset_sample = tf.data.Dataset.from_tensor_slices((tensor_file,truth_file))\n",
    "        datasets.append(dataset_sample)\n",
    "\n",
    "# print(len(datasets))\n",
    "#print(type(dataset))\n",
    "#print(tensors[0][1])\n",
    "# Print number of datasets\n",
    "#print(len(dataset))\n",
    "# print(len(tensors))\n",
    "weights_list = []\n",
    "for tensor, total_events in zip(tensors, n_events):\n",
    "            weights = [tensor.shape[0] / total_events]\n",
    "            weights_list.extend(weights)\n",
    "print(\"weights_list_len\",len(weights_list))\n",
    "\n",
    "#print(weights_list)\n",
    "#print(len(weights_list))\n",
    "dataset = tf.data.Dataset.sample_from_datasets(datasets, weights=weights_list)\n",
    "# Combine the datasets using sample_from_datasets method\n",
    "# This will shuffle the events from all datasets into a single dataset\n",
    "\n",
    "print(type(dataset))\n",
    "# Printout the shape of the first event\n",
    "for x in dataset.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
