{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:36:12.243572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-16 21:36:12.264628: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-16 21:36:12.271124: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: []\n",
      "Found ['/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root', '/scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:36:16.340679: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603424.PhPy8_VBFH125_ttlm15hp20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603425.PhPy8_VBFH125_ttl13l7.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603423.PhPy8_VBFH125_ttlp15hm20.PHYS.e8559_s4159_r15224_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.603422.PhPy8_VBFH125_tth30h20.PHYS.e8559_s4162_r14622_p6284.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4162_r15540_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700901.Sh_2214_Ztt_maxHTpT_Mll10_40_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700903.Sh_2214_Ztt_maxHTpT_Mll10_40_CVBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700794.Sh_2214_Ztt_maxHTpT_CVBV.PHYS.e8514_s4159_r15530_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700792.Sh_2214_Ztt_maxHTpT_BF.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700793.Sh_2214_Ztt_maxHTpT_CFBV.PHYS.e8514_s4159_r15224_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "Reading file /scratch/ucjf-atlas/njsf164/data_higgs_root/user.kilie.Htt_lh_02.mc23_13p6TeV.700902.Sh_2214_Ztt_maxHTpT_Mll10_40_CFBV.PHYS.e8514_s4162_r14622_p6266.smPre_n_0_HS.NOMINAL.root\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "# test GPU\n",
    "# Import tensorflow and test if GPU is available\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# load data and convert them to awkward arrays using uproot\n",
    "import uproot\n",
    "\n",
    "\n",
    "# path to the signal and background files\n",
    "path_sig = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*VBFH*.root\"\n",
    "path_bkg = \"/scratch/ucjf-atlas/njsf164/data_higgs_root/*Ztt*.root\"\n",
    "\n",
    "# glob the files\n",
    "import glob\n",
    "files_sig = glob.glob(path_sig)\n",
    "files_bkg = glob.glob(path_bkg)\n",
    "\n",
    "print(\"Found\", files_sig)\n",
    "\n",
    "\n",
    "# define list of variable that we want to read from the files\n",
    "variables_higgs = [  \n",
    "    \"tau_0_p4\",\n",
    "    \"tau_1_p4\",\n",
    "    \"ditau_deta\",\"ditau_dphi\",\"ditau_dr\",\"ditau_higgspt\",\"ditau_scal_sum_pt\", #\"ditau_mmc_mlm_m\",\n",
    "    \"jet_0_p4\",\n",
    "    \"jet_1_p4\",\n",
    "    \"dijet_p4\", # fixme add dEta\n",
    "    \"met_p4\", \n",
    "    \"n_jets\",\"n_jets_30\",\"n_jets_40\",\"n_electrons\",\"n_muons\",\"n_taus\",\n",
    "]\n",
    "\n",
    "import vector\n",
    "import awkward as ak\n",
    "\n",
    "# use uproot to convert the root files to awkward arrays\n",
    "arrays = []\n",
    "for files in [files_sig, files_bkg]:\n",
    "    arrays.append([])\n",
    "    for file in files:\n",
    "        print(\"Reading file\", file)\n",
    "        f = uproot.open(file)['NOMINAL']\n",
    "        data = f.arrays(variables_higgs, library=\"ak\")\n",
    "        arr = []\n",
    "        for var in variables_higgs:\n",
    "            if 'p4' in var:\n",
    "                # We need to extract the 4-vector pt, eta, phi, mass\n",
    "                p4 = vector.zip({'x':data[var]['fP']['fX'], \n",
    "                                'y':data[var]['fP']['fY'], \n",
    "                                'z':data[var]['fP']['fZ'],\n",
    "                                't':data[var]['fE']})\n",
    "                \n",
    "                arr.append(p4.rho) # pt\n",
    "                arr.append(p4.eta) # eta\n",
    "                arr.append(p4.phi) # phi\n",
    "                arr.append(p4.tau) # mass\n",
    "            \n",
    "            else:\n",
    "                arr.append(data[var])\n",
    "\n",
    "        arrays[-1].append(arr)    \n",
    "\n",
    "print(len(arrays[0]))\n",
    "print(len(arrays[1]))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 (195502, 35) (195502,)\n",
      "0 1 (7156, 35) (7156,)\n",
      "0 2 (209617, 35) (209617,)\n",
      "0 3 (7282, 35) (7282,)\n",
      "0 4 (210515, 35) (210515,)\n",
      "0 5 (1844, 35) (1844,)\n",
      "0 6 (195498, 35) (195498,)\n",
      "0 7 (1878, 35) (1878,)\n",
      "1 0 (1, 35) (1,)\n",
      "1 1 (5619, 35) (5619,)\n",
      "1 2 (1092, 35) (1092,)\n",
      "1 3 (31486, 35) (31486,)\n",
      "1 4 (5, 35) (5,)\n",
      "1 5 (103, 35) (103,)\n",
      "1 6 (26, 35) (26,)\n",
      "1 7 (54, 35) (54,)\n",
      "1 8 (73851, 35) (73851,)\n",
      "1 9 (2694, 35) (2694,)\n",
      "1 10 (13107, 35) (13107,)\n",
      "1 11 (22, 35) (22,)\n",
      "Signal events: 829292\n",
      "Background events: 128060\n",
      "2\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# convert the awkward arrays to tensorflow tensors\n",
    "tensors = []\n",
    "labels = []\n",
    "n_events = []\n",
    "for i,arr_sample in enumerate(arrays):\n",
    "    n_evt = 0\n",
    "    tensors.append([])\n",
    "    labels.append([])\n",
    "    for j, arr_file in enumerate(arr_sample):\n",
    "        tensors_var = []\n",
    "        for arr_var in arr_file:\n",
    "            tensor = tf.constant(ak.to_numpy(arr_var), dtype=tf.float32)\n",
    "            tensors_var.append(tensor)\n",
    "\n",
    "        # stack the tensors along the first axis\n",
    "        tensor_stack = tf.stack(tensors_var, axis=1)\n",
    "        tensors[-1].append(tensor_stack)\n",
    "        n_evt += tensor_stack.shape[0]\n",
    "\n",
    "        # add the label\n",
    "        labels[-1].append(tf.constant(i==0, shape=(tensor.shape[0]), dtype=tf.int32)) # signal files go first, so i==0 is signal\n",
    "        print(i, j, tensors[-1][-1].shape, labels[-1][-1].shape)\n",
    "    n_events.append(n_evt)\n",
    "\n",
    "print(\"Signal events:\", n_events[0])\n",
    "print(\"Background events:\", n_events[1])\n",
    "print(len(tensors))\n",
    "print(type(tensors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'list'>\n",
      "8\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "195502\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "7156\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "209617\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "7282\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "210515\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1844\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "195498\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1878\n",
      "<class 'list'>\n",
      "12\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "5619\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1092\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "31486\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "5\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "103\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "26\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "54\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "73851\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "2694\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "13107\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "22\n",
      "2\n",
      "[0.2357456722119591, 0.008629047428408811, 0.2527662150364407, 0.008780984261273472, 0.2538490664325714, 0.002223583490495507, 0.2357408488204396, 0.002264582318411368, 7.808839606434484e-06, 0.04387786974855536, 0.008527252850226456, 0.24586912384819615, 3.904419803217242e-05, 0.0008043104794627519, 0.0002030298297672966, 0.0004216773387474621, 0.576690613774793, 0.0210370138997345, 0.10235046072153678, 0.00017179447134155865]\n",
      "tf.Tensor(\n",
      "[ 4.75435562e+01  1.62719214e+00  5.07154644e-01  1.34869913e-06\n",
      "  2.86771793e+01  1.62386715e+00 -1.35885978e+00  1.05658375e-01\n",
      "  3.32498550e-03  1.86601448e+00  1.86601734e+00  7.98840256e+01\n",
      "  7.62207336e+01  7.68746872e+01 -5.88225007e-01 -2.71475554e+00\n",
      "  8.21009636e+00  6.61246338e+01  3.41954112e+00  1.86800742e+00\n",
      "  4.54609299e+00  9.46995926e+01  3.01311755e+00  2.80362153e+00\n",
      "  5.30990417e+02  4.75952301e+01  0.00000000e+00 -1.26162064e+00\n",
      "  7.29064504e-03  2.00000000e+00  2.00000000e+00  2.00000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  1.00000000e+00], shape=(35,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 1.06627373e+02  8.09739769e-01  6.83270574e-01  0.00000000e+00\n",
      "  4.57801018e+01  1.09750319e+00 -9.25439954e-01  1.05658375e-01\n",
      "  2.87763417e-01  1.60871053e+00  1.63424516e+00  1.32374298e+02\n",
      "  1.52407471e+02  9.62700500e+01 -2.47654065e-01  3.07703400e+00\n",
      "  8.29026604e+00  3.73139343e+01  4.37012243e+00 -2.60758066e+00\n",
      "  3.24498940e+00  1.28823944e+02  3.11638021e+00 -3.04221082e+00\n",
      "  5.99148132e+02  2.62221432e+01  0.00000000e+00 -6.25937045e-01\n",
      " -2.08655186e-03  3.00000000e+00  2.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  1.00000000e+00], shape=(35,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 6.8692284e+01 -1.0077282e+00 -1.8557801e+00 -1.3486991e-06\n",
      "  5.7635818e+01 -1.2657468e+00 -2.5972049e+00  5.1100040e-04\n",
      "  2.5801861e-01  7.4142480e-01  7.8503782e-01  2.2719673e+02\n",
      "  1.2632810e+02  1.5924152e+02  9.9201268e-01  4.8691240e-01\n",
      "  1.0712102e+01  1.5062659e+02 -2.6854444e+00  2.3041911e+00\n",
      "  1.8994822e+01  1.9063405e+02 -2.2714620e+00  1.3599036e+00\n",
      "  9.8078082e+02  1.1044759e+02  0.0000000e+00 -2.3859110e+00\n",
      " -2.9825033e-03  6.0000000e+00  6.0000000e+00  5.0000000e+00\n",
      "  1.0000000e+00  0.0000000e+00  1.0000000e+00], shape=(35,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 3.2672932e+01 -5.0499111e-01  4.3586013e-01  6.7434956e-07\n",
      "  6.2033741e+01 -1.2007509e+00  1.8065865e+00  5.1099859e-04\n",
      "  6.9575983e-01  1.3707263e+00  1.5371963e+00  1.7203154e+02\n",
      "  9.4706673e+01  1.2904448e+02  1.4425223e+00 -1.7605252e+00\n",
      "  5.0928898e+00  5.2445190e+01 -3.7600067e+00 -1.5443070e+00\n",
      "  2.1579186e-05  1.8061931e+02 -2.2734296e+00 -1.6981910e+00\n",
      "  1.1031129e+03  9.7703781e+01  0.0000000e+00  1.6176784e+00\n",
      " -1.7450552e-02  2.0000000e+00  2.0000000e+00  2.0000000e+00\n",
      "  1.0000000e+00  0.0000000e+00  1.0000000e+00], shape=(35,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[ 5.3350586e+01  7.2684610e-01 -7.2196424e-01 -1.6518123e-06\n",
      "  3.5942661e+01  1.7826521e+00 -1.3706843e+00  5.1099679e-04\n",
      "  1.0558060e+00  6.4872003e-01  1.2391788e+00  1.6367563e+02\n",
      "  8.9293243e+01  1.6891550e+02 -3.2004377e-01  1.8111005e+00\n",
      "  1.5024466e+01  4.6836014e+01  3.2524514e+00 -1.5832102e+00\n",
      "  3.0958440e+00  1.2412085e+02  2.1935017e+00  1.9055903e+00\n",
      "  5.4610895e+02  7.8868416e+01  0.0000000e+00 -1.0045620e+00\n",
      "  2.7509024e-02  5.0000000e+00  3.0000000e+00  2.0000000e+00\n",
      "  1.0000000e+00  0.0000000e+00  1.0000000e+00], shape=(35,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# convert tensors to dataset\n",
    "# Creating a unified list of datasets without distinguishing between signal and background\n",
    "print(type(tensors))\n",
    "print(type(tensors[0]))\n",
    "print(type(tensors[0][0]))\n",
    "\n",
    "datasets = []\n",
    "for tensors_sample in tensors:\n",
    "    print(type(tensors_sample))\n",
    "    print(len(tensors_sample))\n",
    "    for tensor_file in tensors_sample:\n",
    "        print(type(tensor_file))\n",
    "        print(len(tensor_file))\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((tensor_file))\n",
    "        datasets.append(dataset)\n",
    "print(len(tensors))\n",
    "#print(type(dataset))\n",
    "#print(tensors[0][1])\n",
    "# Print number of datasets\n",
    "#print(len(dataset))\n",
    "weights_list = []\n",
    "for i in range(len(tensors)):\n",
    "    weights = [ x.shape[0] / n_events[i] for x in tensors[i]]\n",
    "    weights_list.extend(weights)\n",
    "\n",
    "print(weights_list)\n",
    "dataset = tf.data.Dataset.sample_from_datasets(datasets, weights=weights_list)\n",
    "# Combine the datasets using sample_from_datasets method\n",
    "# This will shuffle the events from all datasets into a single dataset\n",
    "\n",
    "\n",
    "# Printout the shape of the first event\n",
    "for x in dataset.take(5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf gpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
