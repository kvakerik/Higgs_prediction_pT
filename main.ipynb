{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 01:00:24.893613: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-25 01:00:24.903230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742860824.915430 2123448 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742860824.919100 2123448 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 01:00:24.932859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from ModelClass import RegressionModel\n",
    "from DatasetClass import Dataset, DatasetMass\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from src.helpers import make_filter_slice\n",
    "import tensorflow as tf\n",
    "import optuna \n",
    "from optuna_dashboard import run_server\n",
    "import threading\n",
    "#import sys\n",
    "#import logging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "erik_data = \"/scratch/ucjf-atlas/htautau/SM_Htautau_R22/V02_skim_mva_01/*/*/*/*/*H125*.root\"\n",
    "patrik_data = \"/scratch/ucjf-atlas/htautau/SM_Htautau_R22/V02_skim_mva_01/*/*/*/*/*Ztt*.root\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742860832.998950 2123448 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43493 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:41:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = DatasetMass(file_paths=patrik_data, file_name = \"data\")\n",
    "dataset.load_data()\n",
    "dataset.augment_data_phi(n_slices=10)\n",
    "#start_time = time.time()\n",
    "#for batch in dataset.train_dataset.take(1):\n",
    "#    print(\"Batch loaded in:\", time.time() - start_time)\n",
    "#train_batches = dataset.train_dataset.batch(32)\n",
    "#for feature, target in train_batches.take(1):\n",
    "#    print(f\"Feature: {feature.shape}\")\n",
    "#    print(f\"Target: {target.shape}\")\n",
    "\n",
    "#print(len(dataset.train_dataset))\n",
    "#print(len(dataset.dev_dataset))\n",
    "#print(len(dataset.val_dataset))\n",
    "#This block of code iterates through the dataset and extracts the pt values of the labels and stores them in a list\n",
    "#data = [labels.numpy()[0] for features, labels in dataset.train_dataset.take(100000)]\n",
    "\n",
    "#plt.hist(data, bins=100, range=(50, 130), histtype='step', label='pt distribution', density=False)\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.title('pt distribution of the dataset')\n",
    "#plt.xlabel('pt')\n",
    "#plt.ylabel('Number of events')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "features, masses = next(iter(dataset.train_dataset.batch(1000)))\n",
    "\n",
    "#print(features.shape)\n",
    "#print(features)\n",
    "\n",
    "plt.hist(masses, range=(70, 130), bins=50)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(35,), dtype=float32, numpy=\n",
      "array([ 7.9698662e+01,  6.1323375e-01, -8.7493402e-01,  0.0000000e+00,\n",
      "        3.8777607e+01,  3.8384306e-01, -1.8669480e+00, -4.7683716e-07,\n",
      "        2.2939068e-01,  1.9694054e+00,  2.0282004e+00,  7.6542953e+01,\n",
      "        1.1847627e+02,  1.0869468e+02, -5.2226692e-01,  2.9164805e+00,\n",
      "        2.2685047e+01,  6.0651863e+01,  1.3404112e+00, -3.1856185e-01,\n",
      "        6.9703789e+00,  7.5218994e+01,  6.0732043e-01,  2.0889819e+00,\n",
      "        2.3333194e+02,  2.3549999e+01,  0.0000000e+00,  6.1772847e-01,\n",
      "       -1.6468724e-03,  2.0000000e+00,  2.0000000e+00,  2.0000000e+00,\n",
      "        0.0000000e+00,  0.0000000e+00,  2.0000000e+00], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=118.97869873046875>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 21:34:11.876591: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742848633.867110 2916524 service.cc:148] XLA service 0x7f5138046140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742848633.867159 2916524 service.cc:156]   StreamExecutor device (0): NVIDIA L40, Compute Capability 8.9\n",
      "2025-03-24 21:37:13.894024: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742848633.986289 2916524 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1742848634.878876 2916524 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset.train_dataset.take(1):\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.make_slices(n_slices=100)\n",
    "slices = dataset.slices   \n",
    "\n",
    "lorentz_mask = tf.constant(dataset.get_lorentz_mask())  # Shape [35] bool values\n",
    "lorentz_indices = tf.squeeze(tf.where(lorentz_mask), axis=1) # [0 1 2 3 4 5 6 7 13 14 ...] \n",
    "n_vectors = tf.shape(lorentz_indices)[0] // 4 # number of 4-vectors\n",
    "lorentz_indices_4d = tf.reshape(lorentz_indices, (n_vectors, 4))  # [n_vectors, 4]\n",
    "\n",
    "@tf.function\n",
    "def augment_lorentz(data, target):\n",
    "    beta = tf.random.uniform(shape = (), minval=-0.98, maxval=0.98) # Shape ()\n",
    "    #tf.print(\"used beta: \", beta)\n",
    "    gamma = 1.0 / tf.sqrt(1.0 - beta**2) # Shape ()\n",
    "    #tf.print(\"used gamma: \", gamma)\n",
    "    \n",
    "    for i in range(n_vectors):\n",
    "        vec_indices = lorentz_indices_4d[i] # Shape (4,)\n",
    "        pt = data[vec_indices[0]] # scalar values\n",
    "        eta = data[vec_indices[1]]\n",
    "        #tf.print(\"eta: \", eta)\n",
    "        phi = data[vec_indices[2]]\n",
    "        E = data[vec_indices[3]]\n",
    "        #tf.print(\"E: \", E)\n",
    "        #print(E.shape)\n",
    "        \n",
    "        # Convert to Cartesian coordinates\n",
    "        #px = pt * tf.cos(phi)\n",
    "        #py = pt * tf.sin(phi)\n",
    "        pz = pt * tf.sinh(eta) # Shape ()\n",
    "        #tf.print(\"pz: \", pz)\n",
    "\n",
    "        E_prime = gamma * (E - beta * pz) # Shape ()\n",
    "        #tf.print(\"E_prime: \", E_prime)\n",
    "        pz_prime = gamma * (pz - beta * E) \n",
    "        \n",
    "        epsilon = 1e-8\n",
    "        eta_prime = tf.asinh(pz_prime / (pt + epsilon)) # Shape ()\n",
    "        #tf.print(\"eta_prime: \", eta_prime)\n",
    "        update_indices = tf.reshape(vec_indices, [-1, 1])  # Shape (4, 1)\n",
    "        update_values = tf.stack([pt, eta_prime, phi, E_prime]) # Shape (4,)\n",
    "        # Update the tensor\n",
    "        data = tf.tensor_scatter_nd_update(\n",
    "            data,\n",
    "            indices=update_indices,\n",
    "            updates=update_values\n",
    "        )\n",
    "        #print(data.shape)\n",
    "        \n",
    "    return data, target\n",
    "\n",
    "n_events = 10000\n",
    "new_dataset = tf.data.Dataset.sample_from_datasets([s.repeat() for s in slices], weights=[1.]*len(slices))\n",
    "#orig_features, orig_masses = next(iter(new_dataset))\n",
    "#print(orig_features)\n",
    "#print(orig_masses)\n",
    "new_dataset = new_dataset.take(n_events)\n",
    "augmented_dataset = new_dataset.map(augment_lorentz)\n",
    "#new_features, new_masses = next(iter(new_dataset))\n",
    "#print(new_features)š\n",
    "#print(new_masses)\n",
    "#batch_dataset = augmented_dataset.batch(n_events)\n",
    "#print(f\"Number of events in batch_dataset: {len(augmented_dataset)}\")\n",
    "#features, masses = next(iter(batch_dataset))\n",
    "\n",
    "#plt.hist(masses, range=(70, 130), bins=50)\n",
    "#plt.show()\n",
    "\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lorentz_mask = tf.constant(dataset.get_lorentz_mask()) \n",
    "print(lorentz_mask)\n",
    "\n",
    "features = tf.constant([\n",
    "    5.56329613e+01, -3.16469967e-01, -9.03481603e-01, 6.74349565e-07,\n",
    "    5.47039528e+01, -1.49002433e-01, 2.52283901e-01, 1.05658375e-01,\n",
    "    1.67467535e-01, 1.15576553e+00, 1.16783524e+00, 1.38526611e+02,\n",
    "    1.10336914e+02, 1.38102692e+02, 1.74350947e-01, 2.87319326e+00,\n",
    "    1.55200872e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "    0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "    0.00000000e+00, 4.71827660e+01, 0.00000000e+00, -6.81111366e-02,\n",
    "    -1.58858541e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
    "    0.00000000e+00, 1.00000000e+00, 1.00000000e+00\n",
    "], dtype=tf.float32)\n",
    "\n",
    "label = tf.constant(94.92591, dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors((features, label))\n",
    "dataset = dataset.map(augment_lorentz)\n",
    "\n",
    "new_features, new_label = next(iter(dataset))\n",
    "print(new_features)\n",
    "print(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.make_slices(n_slices=10)\n",
    "slices = dataset.slices \n",
    "phi_mask = tf.constant(dataset.get_phi_mask())\n",
    "\n",
    "@tf.function\n",
    "def augment_phi(data, target):\n",
    "    # generate random rotation angle\n",
    "    angle = tf.random.uniform(shape=(tf.shape(data)[0],), minval=-np.pi, maxval=np.pi)\n",
    "    #tf.print(\"angle: \", angle.shape)\n",
    "    #tf.print(\"data: \", data.shape)\n",
    "    # apply rotation\n",
    "    data  = tf.where(phi_mask, data + angle, data)\n",
    "    \n",
    "    # normalize angles between -pi and pi\n",
    "    data = tf.where(phi_mask, tf.math.atan2(tf.sin(data), tf.cos(data)), data)\n",
    "    \n",
    "    return data, target\n",
    "\n",
    "# sample from the slices\n",
    "n_events = 1000\n",
    "new_dataset = tf.data.Dataset.sample_from_datasets([s.repeat() for s in slices], weights=[1.]*len(slices))\n",
    "new_dataset = new_dataset.take(n_events)\n",
    "\n",
    "# apply augmentation\n",
    "new_dataset = new_dataset.map(augment_phi)\n",
    "#aug_dataset = new_dataset.batch(n_events)\n",
    "\n",
    "\n",
    "#print(f\"Number of events in batch_dataset: {len(batch_dataset)}\")\n",
    "#features, masses = next(iter(batch_dataset))\n",
    "#print(features.shape)\n",
    "#print(features)\n",
    "\n",
    "#plt.hist(masses, range=(70, 130), bins=50)\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'batch_size': [3200, 6400],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'epochs': [5, 20, 30]\n",
    "}\n",
    "\n",
    "iterable = list(itertools.product(*param_grid.values()))\n",
    "for params in iterable:\n",
    "    model = RegressionModel(dataset=dataset, batch_size=params[0], initial_learning_rate=params[1], n_epochs=params[2])\n",
    "    model.prepare_dataset()\n",
    "    model.create_normalizer()\n",
    "    model.build_model()\n",
    "    model.train_model()\n",
    "    model.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-25 01:00:42,100] Using an existing study with name 'Higgs_analysis_mass_2' instead of creating a new one.\n",
      "Bottle v0.13.2 server starting up (using WSGIRefServer())...\n",
      "Listening on http://0.0.0.0:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 01:00:42.807776: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742860845.551306 2123576 service.cc:148] XLA service 0x7f12140093a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742860845.551338 2123576 service.cc:156]   StreamExecutor device (0): NVIDIA L40S, Compute Capability 8.9\n",
      "2025-03-25 01:00:45.576787: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742860845.668168 2123576 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/7616\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:32:46\u001b[0m 3s/step - loss: 10304.5186 - mean_absolute_percentage_error: 100.4438 - mean_squared_error: 10304.5186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742860846.245512 2123576 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  23/7616\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:02:10\u001b[0m 1s/step - loss: 10201.1641 - mean_absolute_percentage_error: 99.5307 - mean_squared_error: 10201.1641"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m optuna_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mrun_optuna)\n\u001b[1;32m     45\u001b[0m optuna_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 47\u001b[0m \u001b[43moptuna_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for Optuna to finish before printing results\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  27/7616\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:01:54\u001b[0m 1s/step - loss: 10172.4043 - mean_absolute_percentage_error: 99.3647 - mean_squared_error: 10172.4043"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    model = RegressionModel(\n",
    "                dataset,\n",
    "                n_layers             = trial.suggest_int('n_layers', 1, 3),\n",
    "                hidden_layer_size    = trial.suggest_int('hidden_layer_size', 32, 128, step=24),\n",
    "                initial_learning_rate= trial.suggest_float('initial_learning_rate', 1e-3, 1e-2, log=True),\n",
    "                n_epochs             = trial.suggest_int('n_epochs', 10, 20, step=5),\n",
    "                activation_function  = 'relu',\n",
    "                batch_size           = trial.suggest_int('batch_size', 512, 1024,step=64),\n",
    "                dropout_rate         = trial.suggest_float('dropout_rate', 0.1, 0.5),\n",
    "                weight_decay         = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "\n",
    "            )\n",
    "\n",
    "    model.prepare_dataset()\n",
    "    model.create_normalizer()\n",
    "    model.build_model()\n",
    "    model.train_model()\n",
    "\n",
    "    # Handle based on the number of metrics\n",
    "    evaluation_results = model.model.evaluate(model.dev_batch, verbose=0)\n",
    "    if isinstance(evaluation_results, list):\n",
    "        val_loss = evaluation_results[0]\n",
    "    else:\n",
    "        val_loss = evaluation_results  # If only one value is returned, it's the loss\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "study = optuna.create_study(storage=\"sqlite:///optuna.db\", study_name=\"Higgs_analysis_mass_2\", direction='minimize', load_if_exists=True)\n",
    "\n",
    "def run_dashboard():\n",
    "    server = run_server(\"sqlite:///optuna.db\", host=\"0.0.0.0\", port=8080)\n",
    "    server.run()  # Run dashboard continuously in a separate thread\n",
    "\n",
    "dashboard_thread = threading.Thread(target=run_dashboard)\n",
    "dashboard_thread.daemon = True  # Ensures it stops when the script ends\n",
    "dashboard_thread.start()\n",
    "\n",
    "def run_optuna():\n",
    "    study.optimize(objective, n_trials=100, n_jobs=1)\n",
    "\n",
    "# Run Optuna in a separate thread so the dashboard can be accessed in real-time\n",
    "optuna_thread = threading.Thread(target=run_optuna)\n",
    "optuna_thread.start()\n",
    "\n",
    "optuna_thread.join()  # Wait for Optuna to finish before printing results\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htt_env",
   "language": "python",
   "name": "htt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
