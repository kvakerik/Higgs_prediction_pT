{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 19:56:27.725808: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-19 19:56:27.736873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742410587.748965 3539757 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742410587.752677 3539757 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 19:56:27.766440: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from ModelClass import RegressionModel\n",
    "from DatasetClass import Dataset, DatasetMass\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from src.helpers import make_filter_slice\n",
    "import tensorflow as tf\n",
    "import optuna \n",
    "from optuna_dashboard import run_server\n",
    "import threading\n",
    "import sys\n",
    "import logging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "erik_data = \"/scratch/ucjf-atlas/htautau/SM_Htautau_R22/V02_skim_mva_01/*/*/*/*/*H125*.root\"\n",
    "patrik_data = \"/scratch/ucjf-atlas/htautau/SM_Htautau_R22/V02_skim_mva_01/*/*/*/*/*Ztt*.root\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742410596.261099 3539757 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43493 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:41:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7799005\n"
     ]
    }
   ],
   "source": [
    "dataset = DatasetMass(file_paths=patrik_data, file_name = \"data\")\n",
    "dataset.load_data()\n",
    "print(dataset.train_events)\n",
    "    \n",
    "#dataset.augment_data_phi(n_slices=1000)\n",
    "\n",
    "#train_batches = dataset.train_dataset.batch(32)\n",
    "#for feature, target in train_batches.take(1):\n",
    "#    print(f\"Feature: {feature.shape}\")\n",
    "#    print(f\"Target: {target.shape}\")\n",
    "\n",
    "#print(len(dataset.train_dataset))\n",
    "#print(len(dataset.dev_dataset))\n",
    "#print(len(dataset.val_dataset))\n",
    "#This block of code iterates through the dataset and extracts the pt values of the labels and stores them in a list\n",
    "#data = [labels.numpy()[0] for features, labels in dataset.train_dataset.take(100000)]\n",
    "\n",
    "#plt.hist(data, bins=100, range=(50, 130), histtype='step', label='pt distribution', density=False)\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.title('pt distribution of the dataset')\n",
    "#plt.xlabel('pt')\n",
    "#plt.ylabel('Number of events')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.make_slices(n_slices=100)\n",
    "slices = dataset.slices   \n",
    "\n",
    "lorentz_mask = tf.constant(dataset.get_lorentz_mask())  # Shape [35] bool values\n",
    "lorentz_indices = tf.squeeze(tf.where(lorentz_mask), axis=1) # [0 1 2 3 4 5 6 7 13 14 ...] \n",
    "n_vectors = tf.shape(lorentz_indices)[0] // 4 # number of 4-vectors\n",
    "lorentz_indices_4d = tf.reshape(lorentz_indices, (n_vectors, 4))  # [n_vectors, 4]\n",
    "\n",
    "@tf.function\n",
    "def augment_lorentz(data, target):\n",
    "    beta = tf.random.uniform(shape = (), minval=-0.98, maxval=0.98) # Shape ()\n",
    "    #tf.print(\"used beta: \", beta)\n",
    "    gamma = 1.0 / tf.sqrt(1.0 - beta**2) # Shape ()\n",
    "    #tf.print(\"used gamma: \", gamma)\n",
    "    \n",
    "    for i in range(n_vectors):\n",
    "        vec_indices = lorentz_indices_4d[i] # Shape (4,)\n",
    "        pt = data[vec_indices[0]] # scalar values\n",
    "        eta = data[vec_indices[1]]\n",
    "        #tf.print(\"eta: \", eta)\n",
    "        phi = data[vec_indices[2]]\n",
    "        E = data[vec_indices[3]]\n",
    "        #tf.print(\"E: \", E)\n",
    "        #print(E.shape)\n",
    "        \n",
    "        # Convert to Cartesian coordinates\n",
    "        #px = pt * tf.cos(phi)\n",
    "        #py = pt * tf.sin(phi)\n",
    "        pz = pt * tf.sinh(eta) # Shape ()\n",
    "        #tf.print(\"pz: \", pz)\n",
    "\n",
    "        E_prime = gamma * (E - beta * pz) # Shape ()\n",
    "        #tf.print(\"E_prime: \", E_prime)\n",
    "        pz_prime = gamma * (pz - beta * E) \n",
    "        \n",
    "        epsilon = 1e-8\n",
    "        eta_prime = tf.asinh(pz_prime / (pt + epsilon)) # Shape ()\n",
    "        #tf.print(\"eta_prime: \", eta_prime)\n",
    "        update_indices = tf.reshape(vec_indices, [-1, 1])  # Shape (4, 1)\n",
    "        update_values = tf.stack([pt, eta_prime, phi, E_prime]) # Shape (4,)\n",
    "        # Update the tensor\n",
    "        data = tf.tensor_scatter_nd_update(\n",
    "            data,\n",
    "            indices=update_indices,\n",
    "            updates=update_values\n",
    "        )\n",
    "        #print(data.shape)\n",
    "        \n",
    "    return data, target\n",
    "\n",
    "n_events = 10000\n",
    "new_dataset = tf.data.Dataset.sample_from_datasets([s.repeat() for s in slices], weights=[1.]*len(slices))\n",
    "#orig_features, orig_masses = next(iter(new_dataset))\n",
    "#print(orig_features)\n",
    "#print(orig_masses)\n",
    "new_dataset = new_dataset.take(n_events)\n",
    "augmented_dataset = new_dataset.map(augment_lorentz)\n",
    "#new_features, new_masses = next(iter(new_dataset))\n",
    "#print(new_features)š\n",
    "#print(new_masses)\n",
    "#batch_dataset = augmented_dataset.batch(n_events)\n",
    "#print(f\"Number of events in batch_dataset: {len(augmented_dataset)}\")\n",
    "#features, masses = next(iter(batch_dataset))\n",
    "\n",
    "#plt.hist(masses, range=(70, 130), bins=50)\n",
    "#plt.show()\n",
    "\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ True  True  True  True  True  True  True  True False False False False\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False False False False False False], shape=(35,), dtype=bool)\n",
      "tf.Tensor(\n",
      "[ 5.56329613e+01 -3.16706300e-01 -9.03481603e-01 -7.03347385e-01\n",
      "  5.47039528e+01 -1.49041474e-01  2.52283901e-01 -2.15698794e-01\n",
      "  1.67467535e-01  1.15576553e+00  1.16783524e+00  1.38526611e+02\n",
      "  1.10336914e+02  1.38102692e+02  1.78831533e-01  2.87319326e+00\n",
      "  1.64828949e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.71827660e+01 -1.32284049e-05 -6.81111366e-02\n",
      " -1.58981103e-02  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  1.00000000e+00], shape=(35,), dtype=float32)\n",
      "tf.Tensor(94.92591, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lorentz_mask = tf.constant(dataset.get_lorentz_mask()) \n",
    "print(lorentz_mask)\n",
    "\n",
    "features = tf.constant([\n",
    "    5.56329613e+01, -3.16469967e-01, -9.03481603e-01, 6.74349565e-07,\n",
    "    5.47039528e+01, -1.49002433e-01, 2.52283901e-01, 1.05658375e-01,\n",
    "    1.67467535e-01, 1.15576553e+00, 1.16783524e+00, 1.38526611e+02,\n",
    "    1.10336914e+02, 1.38102692e+02, 1.74350947e-01, 2.87319326e+00,\n",
    "    1.55200872e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "    0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
    "    0.00000000e+00, 4.71827660e+01, 0.00000000e+00, -6.81111366e-02,\n",
    "    -1.58858541e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
    "    0.00000000e+00, 1.00000000e+00, 1.00000000e+00\n",
    "], dtype=tf.float32)\n",
    "\n",
    "label = tf.constant(94.92591, dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors((features, label))\n",
    "dataset = dataset.map(augment_lorentz)\n",
    "\n",
    "new_features, new_label = next(iter(dataset))\n",
    "print(new_features)\n",
    "print(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.make_slices(n_slices=10)\n",
    "slices = dataset.slices \n",
    "phi_mask = tf.constant(dataset.get_phi_mask())\n",
    "\n",
    "@tf.function\n",
    "def augment_phi(data, target):\n",
    "    # generate random rotation angle\n",
    "    angle = tf.random.uniform(shape=(tf.shape(data)[0],), minval=-np.pi, maxval=np.pi)\n",
    "    #tf.print(\"angle: \", angle.shape)\n",
    "    #tf.print(\"data: \", data.shape)\n",
    "    # apply rotation\n",
    "    data  = tf.where(phi_mask, data + angle, data)\n",
    "    \n",
    "    # normalize angles between -pi and pi\n",
    "    data = tf.where(phi_mask, tf.math.atan2(tf.sin(data), tf.cos(data)), data)\n",
    "    \n",
    "    return data, target\n",
    "\n",
    "# sample from the slices\n",
    "n_events = 1000\n",
    "new_dataset = tf.data.Dataset.sample_from_datasets([s.repeat() for s in slices], weights=[1.]*len(slices))\n",
    "new_dataset = new_dataset.take(n_events)\n",
    "\n",
    "# apply augmentation\n",
    "new_dataset = new_dataset.map(augment_phi)\n",
    "#aug_dataset = new_dataset.batch(n_events)\n",
    "\n",
    "\n",
    "#print(f\"Number of events in batch_dataset: {len(batch_dataset)}\")\n",
    "#features, masses = next(iter(batch_dataset))\n",
    "#print(features.shape)\n",
    "#print(features)\n",
    "\n",
    "#plt.hist(masses, range=(70, 130), bins=50)\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n",
      "Building model...\n",
      "Training model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 20:42:51.802874: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 151ms/step - loss: 2335.7473 - mean_squared_error: 2335.7437 - val_loss: 312.1779 - val_mean_squared_error: 312.4890\n",
      "Epoch 2/5\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 150ms/step - loss: 251.6451 - mean_squared_error: 251.6452 - val_loss: 255.4529 - val_mean_squared_error: 255.5452\n",
      "Epoch 3/5\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - loss: 221.5373 - mean_squared_error: 221.5372 - val_loss: 222.5968 - val_mean_squared_error: 222.6384\n",
      "Epoch 4/5\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 149ms/step - loss: 208.6559 - mean_squared_error: 208.6557 - val_loss: 204.9115 - val_mean_squared_error: 204.9481\n",
      "Epoch 5/5\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 152ms/step - loss: 201.6959 - mean_squared_error: 201.6958 - val_loss: 201.3717 - val_mean_squared_error: 201.4131\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RegressionModel.plot_history() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mbuild_model()\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: RegressionModel.plot_history() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'batch_size': [3200, 6400],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'epochs': [5, 20, 30]\n",
    "}\n",
    "\n",
    "iterable = list(itertools.product(*param_grid.values()))\n",
    "for params in iterable:\n",
    "    model = RegressionModel(dataset=dataset, batch_size=params[0], initial_learning_rate=params[1], n_epochs=params[2])\n",
    "    model.prepare_dataset()\n",
    "    model.create_normalizer()\n",
    "    model.build_model()\n",
    "    model.train_model()\n",
    "    model.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 19:57:35,300] A new study created in RDB with name: Higgs_analysis_mass_2\n",
      "Bottle v0.13.2 server starting up (using WSGIRefServer())...\n",
      "Listening on http://0.0.0.0:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n",
      "/singularity/ucjf/venv_tf_218/lib64/python3.9/site-packages/optuna/distributions.py:708: UserWarning: The distribution is specified by [512, 6556] and step=512, but the range is not divisible by `step`. It will be replaced by [512, 6144].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 19:57:35.801286: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742410656.815979 3539925 service.cc:148] XLA service 0x7fcda400a810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742410656.816007 3539925 service.cc:156]   StreamExecutor device (0): NVIDIA L40S, Compute Capability 8.9\n",
      "2025-03-19 19:57:36.835403: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742410656.944428 3539925 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-19 19:57:37.571764: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:37.576017: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 24 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:37.855955: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 796 bytes spill stores, 796 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:37.982991: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 468 bytes spill stores, 468 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:37.983115: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226_0', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.081459: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 296 bytes spill stores, 296 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.101087: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 368 bytes spill stores, 368 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.132342: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484_0', 124 bytes spill stores, 124 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.161698: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 1152 bytes spill stores, 1152 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.168331: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484_0', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.302090: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:38.418799: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/174\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 10397.1182 - mean_squared_error: 10397.1191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742410658.960704 3539925 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 4259.8467 - mean_squared_error: 4259.8467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 19:57:50.514674: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 56 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:50.647109: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 372 bytes spill stores, 372 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:50.651348: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 772 bytes spill stores, 772 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:50.791720: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 1084 bytes spill stores, 1084 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:50.899901: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:51.095180: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 492 bytes spill stores, 492 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:51.293300: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226_0', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:51.350946: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484', 628 bytes spill stores, 628 bytes spill loads\n",
      "\n",
      "2025-03-19 19:57:51.430560: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_484_0', 564 bytes spill stores, 580 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 4245.9995 - mean_squared_error: 4245.9668"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 19:58:15.853295: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 56 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-03-19 19:58:15.948622: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45_0', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-03-19 19:58:15.956436: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 76 bytes spill stores, 76 bytes spill loads\n",
      "\n",
      "2025-03-19 19:58:15.968422: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 372 bytes spill stores, 372 bytes spill loads\n",
      "\n",
      "2025-03-19 19:58:16.013585: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 772 bytes spill stores, 772 bytes spill loads\n",
      "\n",
      "2025-03-19 19:58:16.102772: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 1084 bytes spill stores, 1084 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 216ms/step - loss: 4232.3101 - mean_squared_error: 4232.2451 - val_loss: 418.3317 - val_mean_squared_error: 419.2327\n",
      "Epoch 2/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 315.6752 - mean_squared_error: 315.6960 - val_loss: 269.3182 - val_mean_squared_error: 269.9005\n",
      "Epoch 3/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 195ms/step - loss: 248.7186 - mean_squared_error: 248.7384 - val_loss: 250.1487 - val_mean_squared_error: 250.6241\n",
      "Epoch 4/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 197ms/step - loss: 232.7969 - mean_squared_error: 232.8143 - val_loss: 250.3391 - val_mean_squared_error: 250.6977\n",
      "Epoch 5/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 194ms/step - loss: 226.2121 - mean_squared_error: 226.2267 - val_loss: 258.8209 - val_mean_squared_error: 259.0879\n",
      "Epoch 6/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 223.3355 - mean_squared_error: 223.3460 - val_loss: 229.7745 - val_mean_squared_error: 229.9044\n",
      "Epoch 7/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 213.0070 - mean_squared_error: 213.0156 - val_loss: 223.2449 - val_mean_squared_error: 223.3352\n",
      "Epoch 8/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 198ms/step - loss: 206.7056 - mean_squared_error: 206.7130 - val_loss: 248.0143 - val_mean_squared_error: 248.1780\n",
      "Epoch 9/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 209.1398 - mean_squared_error: 209.1467 - val_loss: 229.2421 - val_mean_squared_error: 229.3403\n",
      "Epoch 10/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 176ms/step - loss: 203.3147 - mean_squared_error: 203.3212 - val_loss: 751.6021 - val_mean_squared_error: 753.9941\n",
      "Epoch 11/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 182ms/step - loss: 223.3552 - mean_squared_error: 223.3620 - val_loss: 216.4354 - val_mean_squared_error: 216.4998\n",
      "Epoch 12/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 199.6091 - mean_squared_error: 199.6147 - val_loss: 214.7348 - val_mean_squared_error: 214.7881\n",
      "Epoch 13/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 196.3077 - mean_squared_error: 196.3129 - val_loss: 286.6471 - val_mean_squared_error: 286.9596\n",
      "Epoch 14/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 205.8043 - mean_squared_error: 205.8088 - val_loss: 215.1580 - val_mean_squared_error: 215.2106\n",
      "Epoch 15/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 182ms/step - loss: 194.6707 - mean_squared_error: 194.6743 - val_loss: 199.9002 - val_mean_squared_error: 199.9059\n",
      "Epoch 16/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 188.9232 - mean_squared_error: 188.9265 - val_loss: 241.4200 - val_mean_squared_error: 241.5790\n",
      "Epoch 17/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 194.4609 - mean_squared_error: 194.4643 - val_loss: 209.7302 - val_mean_squared_error: 209.7741\n",
      "Epoch 18/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 193ms/step - loss: 190.1979 - mean_squared_error: 190.2007 - val_loss: 202.2137 - val_mean_squared_error: 202.2371\n",
      "Epoch 19/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 194ms/step - loss: 187.1929 - mean_squared_error: 187.1953 - val_loss: 198.6531 - val_mean_squared_error: 198.6689\n",
      "Epoch 20/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 182ms/step - loss: 185.0395 - mean_squared_error: 185.0418 - val_loss: 194.4767 - val_mean_squared_error: 194.4857\n",
      "Epoch 21/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 183.0522 - mean_squared_error: 183.0542 - val_loss: 186.4533 - val_mean_squared_error: 186.4490\n",
      "Epoch 22/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 179.5291 - mean_squared_error: 179.5308 - val_loss: 181.0559 - val_mean_squared_error: 181.0517\n",
      "Epoch 23/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 176.8645 - mean_squared_error: 176.8662 - val_loss: 176.5903 - val_mean_squared_error: 176.5908\n",
      "Epoch 24/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 190ms/step - loss: 175.9378 - mean_squared_error: 175.9419 - val_loss: 176.5628 - val_mean_squared_error: 176.5724\n",
      "Epoch 25/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 190ms/step - loss: 176.0442 - mean_squared_error: 176.0467 - val_loss: 172.8074 - val_mean_squared_error: 172.8772\n",
      "Epoch 26/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 167.0809 - mean_squared_error: 167.0864 - val_loss: 166.8029 - val_mean_squared_error: 166.8373\n",
      "Epoch 27/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 160.6165 - mean_squared_error: 160.6195 - val_loss: 175.1860 - val_mean_squared_error: 175.2220\n",
      "Epoch 28/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 186ms/step - loss: 169.7527 - mean_squared_error: 169.7541 - val_loss: 161.8403 - val_mean_squared_error: 161.8513\n",
      "Epoch 29/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 151.9778 - mean_squared_error: 151.9783 - val_loss: 157.3003 - val_mean_squared_error: 157.2906\n",
      "Epoch 30/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 147.7861 - mean_squared_error: 147.7867 - val_loss: 163.6956 - val_mean_squared_error: 163.6929\n",
      "Epoch 31/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 148.3119 - mean_squared_error: 148.3106 - val_loss: 156.4266 - val_mean_squared_error: 156.4003\n",
      "Epoch 32/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 175ms/step - loss: 145.0578 - mean_squared_error: 145.0558 - val_loss: 156.9187 - val_mean_squared_error: 156.8921\n",
      "Epoch 33/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 144.3322 - mean_squared_error: 144.3303 - val_loss: 162.8080 - val_mean_squared_error: 162.7998\n",
      "Epoch 34/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 148.3074 - mean_squared_error: 148.3062 - val_loss: 174.2364 - val_mean_squared_error: 174.2723\n",
      "Epoch 35/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 150.1877 - mean_squared_error: 150.1920 - val_loss: 222.3346 - val_mean_squared_error: 222.5405\n",
      "Epoch 36/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 191.8110 - mean_squared_error: 191.8088 - val_loss: 170.6055 - val_mean_squared_error: 170.5936\n",
      "Epoch 37/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 177ms/step - loss: 152.6860 - mean_squared_error: 152.6841 - val_loss: 161.1917 - val_mean_squared_error: 161.1765\n",
      "Epoch 38/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 145.9619 - mean_squared_error: 145.9604 - val_loss: 164.6795 - val_mean_squared_error: 164.6900\n",
      "Epoch 39/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 180ms/step - loss: 144.5656 - mean_squared_error: 144.5642 - val_loss: 148.1441 - val_mean_squared_error: 148.1149\n",
      "Epoch 40/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 141.0859 - mean_squared_error: 141.0848 - val_loss: 149.9063 - val_mean_squared_error: 149.8848\n",
      "Epoch 41/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 140.5155 - mean_squared_error: 140.5146 - val_loss: 149.0988 - val_mean_squared_error: 149.0782\n",
      "Epoch 42/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 139.7523 - mean_squared_error: 139.7515 - val_loss: 148.0331 - val_mean_squared_error: 148.0121\n",
      "Epoch 43/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 139.1612 - mean_squared_error: 139.1605 - val_loss: 144.7944 - val_mean_squared_error: 144.7664\n",
      "Epoch 44/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 188ms/step - loss: 138.1038 - mean_squared_error: 138.1033 - val_loss: 146.6541 - val_mean_squared_error: 146.6484\n",
      "Epoch 45/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 138.5835 - mean_squared_error: 138.5826 - val_loss: 150.2171 - val_mean_squared_error: 150.1980\n",
      "Epoch 46/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 178ms/step - loss: 136.9611 - mean_squared_error: 136.9606 - val_loss: 176.3665 - val_mean_squared_error: 176.4422\n",
      "Epoch 47/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 141.8741 - mean_squared_error: 141.8753 - val_loss: 200.0028 - val_mean_squared_error: 200.1662\n",
      "Epoch 48/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 153.9655 - mean_squared_error: 153.9649 - val_loss: 162.7991 - val_mean_squared_error: 162.8219\n",
      "Epoch 49/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 140.1542 - mean_squared_error: 140.1544 - val_loss: 162.1065 - val_mean_squared_error: 162.1348\n",
      "Epoch 50/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 141.7163 - mean_squared_error: 141.7175 - val_loss: 162.1784 - val_mean_squared_error: 162.2026\n",
      "Epoch 51/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 190ms/step - loss: 144.4826 - mean_squared_error: 144.4835 - val_loss: 154.1286 - val_mean_squared_error: 154.1283\n",
      "Epoch 52/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 140.2446 - mean_squared_error: 140.2453 - val_loss: 151.3707 - val_mean_squared_error: 151.3605\n",
      "Epoch 53/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 137.5178 - mean_squared_error: 137.5181 - val_loss: 149.1831 - val_mean_squared_error: 149.1647\n",
      "Epoch 54/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 135.1770 - mean_squared_error: 135.1769 - val_loss: 147.7873 - val_mean_squared_error: 147.7638\n",
      "Epoch 55/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 133.7350 - mean_squared_error: 133.7348 - val_loss: 146.9035 - val_mean_squared_error: 146.8774\n",
      "Epoch 56/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 182ms/step - loss: 132.7731 - mean_squared_error: 132.7728 - val_loss: 146.7031 - val_mean_squared_error: 146.6756\n",
      "Epoch 57/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 177ms/step - loss: 132.2867 - mean_squared_error: 132.2862 - val_loss: 145.9891 - val_mean_squared_error: 145.9608\n",
      "Epoch 58/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 131.6737 - mean_squared_error: 131.6732 - val_loss: 145.1260 - val_mean_squared_error: 145.0971\n",
      "Epoch 59/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 177ms/step - loss: 131.2156 - mean_squared_error: 131.2151 - val_loss: 144.7373 - val_mean_squared_error: 144.7092\n",
      "Epoch 60/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 130.9304 - mean_squared_error: 130.9299 - val_loss: 144.1168 - val_mean_squared_error: 144.0887\n",
      "Epoch 61/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 130.5343 - mean_squared_error: 130.5338 - val_loss: 143.6421 - val_mean_squared_error: 143.6144\n",
      "Epoch 62/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 186ms/step - loss: 130.1884 - mean_squared_error: 130.1880 - val_loss: 143.2049 - val_mean_squared_error: 143.1765\n",
      "Epoch 63/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 181ms/step - loss: 129.8694 - mean_squared_error: 129.8691 - val_loss: 142.7502 - val_mean_squared_error: 142.7213\n",
      "Epoch 64/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 129.6136 - mean_squared_error: 129.6134 - val_loss: 142.0590 - val_mean_squared_error: 142.0302\n",
      "Epoch 65/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 129.3416 - mean_squared_error: 129.3416 - val_loss: 141.3868 - val_mean_squared_error: 141.3579\n",
      "Epoch 66/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 182ms/step - loss: 129.0394 - mean_squared_error: 129.0396 - val_loss: 140.7784 - val_mean_squared_error: 140.7500\n",
      "Epoch 67/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 128.6011 - mean_squared_error: 128.6013 - val_loss: 140.3665 - val_mean_squared_error: 140.3388\n",
      "Epoch 68/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 184ms/step - loss: 128.1291 - mean_squared_error: 128.1293 - val_loss: 140.1976 - val_mean_squared_error: 140.1703\n",
      "Epoch 69/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 179ms/step - loss: 127.6968 - mean_squared_error: 127.6968 - val_loss: 140.0218 - val_mean_squared_error: 139.9946\n",
      "Epoch 70/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 187ms/step - loss: 127.3142 - mean_squared_error: 127.3141 - val_loss: 139.8048 - val_mean_squared_error: 139.7782\n",
      "Epoch 71/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 179ms/step - loss: 126.9810 - mean_squared_error: 126.9808 - val_loss: 139.5659 - val_mean_squared_error: 139.5401\n",
      "Epoch 72/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 126.6961 - mean_squared_error: 126.6957 - val_loss: 139.4772 - val_mean_squared_error: 139.4516\n",
      "Epoch 73/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 179ms/step - loss: 126.4771 - mean_squared_error: 126.4766 - val_loss: 139.4731 - val_mean_squared_error: 139.4473\n",
      "Epoch 74/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 189ms/step - loss: 126.3420 - mean_squared_error: 126.3414 - val_loss: 139.4422 - val_mean_squared_error: 139.4161\n",
      "Epoch 75/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 183ms/step - loss: 126.2455 - mean_squared_error: 126.2450 - val_loss: 139.3793 - val_mean_squared_error: 139.3537\n",
      "Epoch 76/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 126.1696 - mean_squared_error: 126.1691 - val_loss: 139.3363 - val_mean_squared_error: 139.3113\n",
      "Epoch 77/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 180ms/step - loss: 126.0803 - mean_squared_error: 126.0799 - val_loss: 139.3076 - val_mean_squared_error: 139.2823\n",
      "Epoch 78/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 125.9993 - mean_squared_error: 125.9989 - val_loss: 139.2949 - val_mean_squared_error: 139.2695\n",
      "Epoch 79/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 186ms/step - loss: 125.9476 - mean_squared_error: 125.9472 - val_loss: 139.2896 - val_mean_squared_error: 139.2646\n",
      "Epoch 80/80\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 185ms/step - loss: 125.9185 - mean_squared_error: 125.9181 - val_loss: 139.2870 - val_mean_squared_error: 139.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 20:40:52,362] Trial 0 finished with value: 139.28695678710938 and parameters: {'n_layers': 4, 'hidden_layer_size': 694, 'initial_learning_rate': 0.0012174952722646558, 'n_epochs': 80, 'batch_size': 5632}. Best is trial 0 with value: 139.28695678710938.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n",
      "Building model...\n",
      "Training model...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 20:40:52.505745: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 142ms/step - loss: 3986.0037 - mean_squared_error: 3986.0537 - val_loss: 1471.4456 - val_mean_squared_error: 1475.8049\n",
      "Epoch 2/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 134ms/step - loss: 539.0031 - mean_squared_error: 539.0649 - val_loss: 596.9026 - val_mean_squared_error: 600.7264\n",
      "Epoch 3/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - loss: 377.4531 - mean_squared_error: 377.5020 - val_loss: 577.5024 - val_mean_squared_error: 580.3884\n",
      "Epoch 4/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - loss: 348.3266 - mean_squared_error: 348.3655 - val_loss: 587.8312 - val_mean_squared_error: 590.1826\n",
      "Epoch 5/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - loss: 331.3771 - mean_squared_error: 331.4058 - val_loss: 401.4754 - val_mean_squared_error: 403.6927\n",
      "Epoch 6/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - loss: 292.2504 - mean_squared_error: 292.2764 - val_loss: 439.9386 - val_mean_squared_error: 441.9095\n",
      "Epoch 7/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 289.1582 - mean_squared_error: 289.1823 - val_loss: 398.1836 - val_mean_squared_error: 400.1928\n",
      "Epoch 8/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 278.1493 - mean_squared_error: 278.1726 - val_loss: 367.6398 - val_mean_squared_error: 369.6938\n",
      "Epoch 9/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 269.7166 - mean_squared_error: 269.7388 - val_loss: 339.9995 - val_mean_squared_error: 342.1063\n",
      "Epoch 10/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - loss: 260.8512 - mean_squared_error: 260.8719 - val_loss: 309.5841 - val_mean_squared_error: 311.7262\n",
      "Epoch 11/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - loss: 252.1579 - mean_squared_error: 252.1776 - val_loss: 295.9816 - val_mean_squared_error: 298.1242\n",
      "Epoch 12/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - loss: 246.5301 - mean_squared_error: 246.5488 - val_loss: 303.4837 - val_mean_squared_error: 305.6069\n",
      "Epoch 13/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 133ms/step - loss: 244.2240 - mean_squared_error: 244.2412 - val_loss: 283.3530 - val_mean_squared_error: 285.4700\n",
      "Epoch 14/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 237.9092 - mean_squared_error: 237.9247 - val_loss: 234.2753 - val_mean_squared_error: 236.4637\n",
      "Epoch 15/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 227.8340 - mean_squared_error: 227.8483 - val_loss: 228.3869 - val_mean_squared_error: 230.6294\n",
      "Epoch 16/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 223.9747 - mean_squared_error: 223.9878 - val_loss: 227.0036 - val_mean_squared_error: 229.1803\n",
      "Epoch 17/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - loss: 220.1556 - mean_squared_error: 220.1677 - val_loss: 220.3505 - val_mean_squared_error: 222.4508\n",
      "Epoch 18/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 216.6761 - mean_squared_error: 216.6873 - val_loss: 234.1417 - val_mean_squared_error: 236.2082\n",
      "Epoch 19/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 215.6933 - mean_squared_error: 215.7036 - val_loss: 229.1580 - val_mean_squared_error: 231.1208\n",
      "Epoch 20/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - loss: 211.4086 - mean_squared_error: 211.4181 - val_loss: 219.3022 - val_mean_squared_error: 221.2483\n",
      "Epoch 21/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - loss: 208.0359 - mean_squared_error: 208.0446 - val_loss: 213.8096 - val_mean_squared_error: 215.7355\n",
      "Epoch 22/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 133ms/step - loss: 205.3522 - mean_squared_error: 205.3602 - val_loss: 211.8909 - val_mean_squared_error: 213.7989\n",
      "Epoch 23/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 138ms/step - loss: 203.2142 - mean_squared_error: 203.2216 - val_loss: 207.9811 - val_mean_squared_error: 209.8803\n",
      "Epoch 24/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 136ms/step - loss: 201.1497 - mean_squared_error: 201.1564 - val_loss: 210.1435 - val_mean_squared_error: 212.0154\n",
      "Epoch 25/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - loss: 200.0484 - mean_squared_error: 200.0547 - val_loss: 205.9103 - val_mean_squared_error: 207.7699\n",
      "Epoch 26/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - loss: 198.7911 - mean_squared_error: 198.7966 - val_loss: 200.7358 - val_mean_squared_error: 202.5813\n",
      "Epoch 27/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 196.2695 - mean_squared_error: 196.2746 - val_loss: 200.0547 - val_mean_squared_error: 201.8705\n",
      "Epoch 28/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 128ms/step - loss: 195.2187 - mean_squared_error: 195.2233 - val_loss: 197.3550 - val_mean_squared_error: 199.1582\n",
      "Epoch 29/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - loss: 193.5507 - mean_squared_error: 193.5550 - val_loss: 198.3325 - val_mean_squared_error: 200.1266\n",
      "Epoch 30/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 133ms/step - loss: 192.7884 - mean_squared_error: 192.7926 - val_loss: 197.2252 - val_mean_squared_error: 199.0238\n",
      "Epoch 31/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 191.9068 - mean_squared_error: 191.9106 - val_loss: 195.6474 - val_mean_squared_error: 197.4443\n",
      "Epoch 32/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 191.0012 - mean_squared_error: 191.0049 - val_loss: 194.7001 - val_mean_squared_error: 196.4937\n",
      "Epoch 33/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - loss: 190.3721 - mean_squared_error: 190.3755 - val_loss: 194.1477 - val_mean_squared_error: 195.9371\n",
      "Epoch 34/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 135ms/step - loss: 189.6242 - mean_squared_error: 189.6274 - val_loss: 194.0874 - val_mean_squared_error: 195.8691\n",
      "Epoch 35/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 142ms/step - loss: 189.3200 - mean_squared_error: 189.3232 - val_loss: 191.4753 - val_mean_squared_error: 193.2626\n",
      "Epoch 36/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 138ms/step - loss: 189.0101 - mean_squared_error: 189.0130 - val_loss: 191.1969 - val_mean_squared_error: 192.9780\n",
      "Epoch 37/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 139ms/step - loss: 188.3703 - mean_squared_error: 188.3731 - val_loss: 190.8617 - val_mean_squared_error: 192.6414\n",
      "Epoch 38/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 137ms/step - loss: 188.1539 - mean_squared_error: 188.1567 - val_loss: 190.6282 - val_mean_squared_error: 192.4102\n",
      "Epoch 39/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 136ms/step - loss: 187.9052 - mean_squared_error: 187.9079 - val_loss: 190.5596 - val_mean_squared_error: 192.3421\n",
      "Epoch 40/40\n",
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 142ms/step - loss: 187.7635 - mean_squared_error: 187.7662 - val_loss: 190.5329 - val_mean_squared_error: 192.3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 21:02:48,098] Trial 1 finished with value: 190.5328826904297 and parameters: {'n_layers': 1, 'hidden_layer_size': 261, 'initial_learning_rate': 0.006968176745043158, 'n_epochs': 40, 'batch_size': 4096}. Best is trial 0 with value: 139.28695678710938.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n",
      "Building model...\n",
      "Training model...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 21:02:49.674467: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-03-19 21:02:49.798100: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537_0', 148 bytes spill stores, 148 bytes spill loads\n",
      "\n",
      "2025-03-19 21:02:49.844687: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537', 368 bytes spill stores, 368 bytes spill loads\n",
      "\n",
      "2025-03-19 21:02:49.858097: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537', 320 bytes spill stores, 320 bytes spill loads\n",
      "\n",
      "2025-03-19 21:02:50.052682: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537', 1152 bytes spill stores, 1152 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10058.5459 - mean_squared_error: 10058.5469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 21:03:01.919884: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_537_0', 488 bytes spill stores, 488 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 187ms/step - loss: 10046.4648 - mean_squared_error: 10046.2686 - val_loss: 3201.9531 - val_mean_squared_error: 3201.7644\n",
      "Epoch 2/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 172ms/step - loss: 1953.5433 - mean_squared_error: 1953.5240 - val_loss: 1124.8763 - val_mean_squared_error: 1124.8728\n",
      "Epoch 3/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 171ms/step - loss: 1036.0881 - mean_squared_error: 1036.0802 - val_loss: 788.7794 - val_mean_squared_error: 788.8259\n",
      "Epoch 4/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 171ms/step - loss: 733.2595 - mean_squared_error: 733.2560 - val_loss: 574.0519 - val_mean_squared_error: 574.1395\n",
      "Epoch 5/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - loss: 541.2865 - mean_squared_error: 541.2862 - val_loss: 456.2789 - val_mean_squared_error: 456.3788\n",
      "Epoch 6/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 169ms/step - loss: 436.5170 - mean_squared_error: 436.5180 - val_loss: 390.4088 - val_mean_squared_error: 390.5108\n",
      "Epoch 7/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 169ms/step - loss: 377.7552 - mean_squared_error: 377.7567 - val_loss: 348.3196 - val_mean_squared_error: 348.4165\n",
      "Epoch 8/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 166ms/step - loss: 338.9779 - mean_squared_error: 338.9798 - val_loss: 319.7617 - val_mean_squared_error: 319.8587\n",
      "Epoch 9/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 168ms/step - loss: 313.0052 - mean_squared_error: 313.0073 - val_loss: 301.9774 - val_mean_squared_error: 302.0746\n",
      "Epoch 10/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - loss: 296.2396 - mean_squared_error: 296.2418 - val_loss: 289.7803 - val_mean_squared_error: 289.8772\n",
      "Epoch 11/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 174ms/step - loss: 284.3468 - mean_squared_error: 284.3490 - val_loss: 280.2467 - val_mean_squared_error: 280.3434\n",
      "Epoch 12/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 171ms/step - loss: 275.1022 - mean_squared_error: 275.1045 - val_loss: 272.7184 - val_mean_squared_error: 272.8142\n",
      "Epoch 13/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 176ms/step - loss: 267.9579 - mean_squared_error: 267.9601 - val_loss: 266.5637 - val_mean_squared_error: 266.6588\n",
      "Epoch 14/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 168ms/step - loss: 262.4640 - mean_squared_error: 262.4662 - val_loss: 261.7017 - val_mean_squared_error: 261.7964\n",
      "Epoch 15/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - loss: 258.0162 - mean_squared_error: 258.0184 - val_loss: 257.6466 - val_mean_squared_error: 257.7415\n",
      "Epoch 16/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 172ms/step - loss: 254.2937 - mean_squared_error: 254.2959 - val_loss: 254.1541 - val_mean_squared_error: 254.2498\n",
      "Epoch 17/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - loss: 251.1548 - mean_squared_error: 251.1570 - val_loss: 251.0048 - val_mean_squared_error: 251.1011\n",
      "Epoch 18/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 172ms/step - loss: 248.4870 - mean_squared_error: 248.4893 - val_loss: 248.5845 - val_mean_squared_error: 248.6814\n",
      "Epoch 19/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 165ms/step - loss: 246.1946 - mean_squared_error: 246.1968 - val_loss: 246.7600 - val_mean_squared_error: 246.8572\n",
      "Epoch 20/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - loss: 244.3027 - mean_squared_error: 244.3050 - val_loss: 245.4088 - val_mean_squared_error: 245.5065\n",
      "Epoch 21/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 169ms/step - loss: 242.7274 - mean_squared_error: 242.7296 - val_loss: 244.3028 - val_mean_squared_error: 244.4005\n",
      "Epoch 22/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 172ms/step - loss: 241.4961 - mean_squared_error: 241.4983 - val_loss: 243.3834 - val_mean_squared_error: 243.4808\n",
      "Epoch 23/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 168ms/step - loss: 240.5566 - mean_squared_error: 240.5588 - val_loss: 242.6497 - val_mean_squared_error: 242.7465\n",
      "Epoch 24/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 169ms/step - loss: 239.8357 - mean_squared_error: 239.8380 - val_loss: 242.1567 - val_mean_squared_error: 242.2526\n",
      "Epoch 25/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 170ms/step - loss: 239.3136 - mean_squared_error: 239.3158 - val_loss: 241.8180 - val_mean_squared_error: 241.9135\n",
      "Epoch 26/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 172ms/step - loss: 238.9428 - mean_squared_error: 238.9450 - val_loss: 241.4924 - val_mean_squared_error: 241.5877\n",
      "Epoch 27/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 171ms/step - loss: 238.6381 - mean_squared_error: 238.6403 - val_loss: 241.2906 - val_mean_squared_error: 241.3862\n",
      "Epoch 28/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 176ms/step - loss: 238.4282 - mean_squared_error: 238.4304 - val_loss: 241.2039 - val_mean_squared_error: 241.2994\n",
      "Epoch 29/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 168ms/step - loss: 238.3411 - mean_squared_error: 238.3433 - val_loss: 241.1619 - val_mean_squared_error: 241.2574\n",
      "Epoch 30/30\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 166ms/step - loss: 238.2962 - mean_squared_error: 238.2984 - val_loss: 241.1548 - val_mean_squared_error: 241.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 21:19:31,176] Trial 2 finished with value: 241.15484619140625 and parameters: {'n_layers': 5, 'hidden_layer_size': 115, 'initial_learning_rate': 0.00037597021029674486, 'n_epochs': 30, 'batch_size': 5120}. Best is trial 0 with value: 139.28695678710938.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching datasets...\n",
      "Building model...\n",
      "Training model...\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 21:19:31.305193: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 145ms/step - loss: 6484.5322 - mean_squared_error: 6484.4580 - val_loss: 1290.6890 - val_mean_squared_error: 1290.4937\n",
      "Epoch 2/70\n",
      "\u001b[1m238/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 918.2609 - mean_squared_error: 918.2609"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m optuna_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mrun_optuna)\n\u001b[1;32m     37\u001b[0m optuna_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 39\u001b[0m \u001b[43moptuna_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for Optuna to finish before printing results\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    model = RegressionModel(\n",
    "                dataset,\n",
    "                n_layers             = trial.suggest_int('n_layers', 1, 5),\n",
    "                hidden_layer_size    = trial.suggest_int('hidden_layer_size', 32, 1024),\n",
    "                initial_learning_rate= trial.suggest_float('initial_learning_rate', 1e-4, 1e-2, log=True),\n",
    "                n_epochs             = trial.suggest_int('n_epochs', 10, 100, step=10),\n",
    "                activation_function  = 'relu',\n",
    "                batch_size           = trial.suggest_int('batch_size', 512, 6556,step=512),\n",
    "\n",
    "    )\n",
    "\n",
    "    model.prepare_dataset()\n",
    "    model.create_normalizer()\n",
    "    model.build_model()\n",
    "    model.train_model()\n",
    "\n",
    "    val_loss, _ = model.model.evaluate(model.val_batch, verbose=0)\n",
    "    return val_loss\n",
    "\n",
    "study = optuna.create_study(storage=\"sqlite:///optuna.db\", study_name=\"Higgs_analysis_mass_2\", direction='minimize', load_if_exists=True)\n",
    "\n",
    "def run_dashboard():\n",
    "    server = run_server(\"sqlite:///optuna.db\", host=\"0.0.0.0\", port=8080)\n",
    "    server.run()  # Run dashboard continuously in a separate thread\n",
    "\n",
    "dashboard_thread = threading.Thread(target=run_dashboard)\n",
    "dashboard_thread.daemon = True  # Ensures it stops when the script ends\n",
    "dashboard_thread.start()\n",
    "\n",
    "def run_optuna():\n",
    "    study.optimize(objective, n_trials=100, n_jobs=1)\n",
    "\n",
    "# Run Optuna in a separate thread so the dashboard can be accessed in real-time\n",
    "optuna_thread = threading.Thread(target=run_optuna)\n",
    "optuna_thread.start()\n",
    "\n",
    "optuna_thread.join()  # Wait for Optuna to finish before printing results\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "print(\"Best trial:\", study.best_trial.params)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htt_env",
   "language": "python",
   "name": "htt_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
